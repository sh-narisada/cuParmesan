diff --git a/concrete-core-bench/src/cuda.rs b/concrete-core-bench/src/cuda.rs
index f859082a..08085a43 100644
--- a/concrete-core-bench/src/cuda.rs
+++ b/concrete-core-bench/src/cuda.rs
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 use crate::benchmark::BenchmarkFixture;
 use concrete_core::prelude::*;
 use concrete_core_fixture::fixture::*;
@@ -45,7 +46,12 @@ bench! {
         CudaLweCiphertextVector, CudaLweCiphertextVector)),
     ((BinaryKeyDistribution, BinaryKeyDistribution), LweCiphertextVectorDiscardingBootstrapFixture2, (CudaFourierLweBootstrapKey,
         CudaGlweCiphertextVector,
-        CudaLweCiphertextVector, CudaLweCiphertextVector))
+        CudaLweCiphertextVector, CudaLweCiphertextVector)),
+    ((BinaryKeyDistribution),
+        LweCiphertextVectorDiscardingOppositeFixture, (CudaLweCiphertextVector,
+        CudaLweCiphertextVector)),
+    ((BinaryKeyDistribution),
+        LweCiphertextVectorDiscardingAdditionFixture, (CudaLweCiphertextVector, CudaLweCiphertextVector))
 }
 
 macro_rules! bench_amortized {
diff --git a/concrete-core-fixture/src/fixture/lwe_ciphertext_vector_discarding_opposite.rs b/concrete-core-fixture/src/fixture/lwe_ciphertext_vector_discarding_opposite.rs
new file mode 100644
index 00000000..071c12a4
--- /dev/null
+++ b/concrete-core-fixture/src/fixture/lwe_ciphertext_vector_discarding_opposite.rs
@@ -0,0 +1,186 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
+use concrete_core::commons::numeric::UnsignedInteger;
+use concrete_core::prelude::{
+    DispersionParameter, LogStandardDev, LweCiphertextCount,
+    LweCiphertextVectorDiscardingOppositeEngine, LweCiphertextVectorEntity, LweDimension, Variance,
+};
+
+use crate::fixture::Fixture;
+use crate::generation::prototyping::{
+    PrototypesLweCiphertextVector, PrototypesLweSecretKey, PrototypesPlaintextVector,
+};
+use crate::generation::synthesizing::SynthesizesLweCiphertextVector;
+use crate::generation::{IntegerPrecision, KeyDistributionMarker, Maker};
+use crate::raw::generation::RawUnsignedIntegers;
+use crate::raw::statistical_test::assert_noise_distribution;
+
+/// A fixture for the types implementing the `LweCiphertextVectorDiscardingOppositeEngine`
+/// trait.
+pub struct LweCiphertextVectorDiscardingOppositeFixture;
+
+#[derive(Debug)]
+pub struct LweCiphertextVectorDiscardingOppositeParameters {
+    pub lwe_ciphertext_count: LweCiphertextCount,
+    pub noise: Variance,
+    pub lwe_dimension: LweDimension,
+}
+
+#[allow(clippy::type_complexity)]
+impl<Precision, KeyDistribution, Engine, InputCiphertextVector, OutputCiphertextVector>
+    Fixture<Precision, (KeyDistribution,), Engine, (InputCiphertextVector, OutputCiphertextVector)>
+    for LweCiphertextVectorDiscardingOppositeFixture
+where
+    Precision: IntegerPrecision,
+    KeyDistribution: KeyDistributionMarker,
+    Engine:
+        LweCiphertextVectorDiscardingOppositeEngine<InputCiphertextVector, OutputCiphertextVector>,
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+    Maker: SynthesizesLweCiphertextVector<Precision, KeyDistribution, InputCiphertextVector>
+        + SynthesizesLweCiphertextVector<Precision, KeyDistribution, OutputCiphertextVector>,
+{
+    type Parameters = LweCiphertextVectorDiscardingOppositeParameters;
+    type RepetitionPrototypes =
+        <Maker as PrototypesLweSecretKey<Precision, KeyDistribution>>::LweSecretKeyProto;
+    type SamplePrototypes = (
+        <Maker as PrototypesPlaintextVector<Precision>>::PlaintextVectorProto,
+        <Maker as PrototypesLweCiphertextVector<
+            Precision,
+            KeyDistribution,
+        >>::LweCiphertextVectorProto,
+        <Maker as PrototypesLweCiphertextVector<
+            Precision,
+            KeyDistribution,
+        >>::LweCiphertextVectorProto,
+    );
+    type PreExecutionContext = (InputCiphertextVector, OutputCiphertextVector);
+    type PostExecutionContext = (InputCiphertextVector, OutputCiphertextVector);
+    type Criteria = (Variance,);
+    type Outcome = (Vec<Precision::Raw>, Vec<Precision::Raw>);
+
+    fn generate_parameters_iterator() -> Box<dyn Iterator<Item = Self::Parameters>> {
+        Box::new(
+            vec![LweCiphertextVectorDiscardingOppositeParameters {
+                lwe_ciphertext_count: LweCiphertextCount(1),
+                noise: Variance(LogStandardDev::from_log_standard_dev(-15.).get_variance()),
+                lwe_dimension: LweDimension(60),
+            }]
+            .into_iter(),
+        )
+    }
+
+    fn generate_random_repetition_prototypes(
+        parameters: &Self::Parameters,
+        maker: &mut Maker,
+    ) -> Self::RepetitionPrototypes {
+        maker.new_lwe_secret_key(parameters.lwe_dimension)
+    }
+
+    fn generate_random_sample_prototypes(
+        parameters: &Self::Parameters,
+        maker: &mut Maker,
+        repetition_proto: &Self::RepetitionPrototypes,
+    ) -> Self::SamplePrototypes {
+        let proto_secret_key = repetition_proto;
+        let raw_plaintext_vector = Precision::Raw::uniform_vec(parameters.lwe_ciphertext_count.0);
+        let proto_plaintext_vector =
+            maker.transform_raw_vec_to_plaintext_vector(&raw_plaintext_vector);
+        let proto_input_ciphertext_vector = maker
+            .encrypt_plaintext_vector_to_lwe_ciphertext_vector(
+                proto_secret_key,
+                &proto_plaintext_vector,
+                parameters.noise,
+            );
+        let proto_output_ciphertext_vector = maker
+            .trivially_encrypt_zeros_to_lwe_ciphertext_vector(
+                parameters.lwe_dimension,
+                parameters.lwe_ciphertext_count,
+            );
+        (
+            proto_plaintext_vector,
+            proto_input_ciphertext_vector,
+            proto_output_ciphertext_vector,
+        )
+    }
+
+    fn prepare_context(
+        _parameters: &Self::Parameters,
+        maker: &mut Maker,
+        _repetition_proto: &Self::RepetitionPrototypes,
+        sample_proto: &Self::SamplePrototypes,
+    ) -> Self::PreExecutionContext {
+        let (_, proto_input_ciphertext_vector, proto_output_ciphertext_vector) = sample_proto;
+        let synth_input_ciphertext_vector =
+            maker.synthesize_lwe_ciphertext_vector(proto_input_ciphertext_vector);
+        let synth_output_ciphertext_vector =
+            maker.synthesize_lwe_ciphertext_vector(proto_output_ciphertext_vector);
+        (
+            synth_input_ciphertext_vector,
+            synth_output_ciphertext_vector,
+        )
+    }
+
+    fn execute_engine(
+        _parameters: &Self::Parameters,
+        engine: &mut Engine,
+        context: Self::PreExecutionContext,
+    ) -> Self::PostExecutionContext {
+        let (input_ciphertext_vector, mut output_ciphertext_vector) = context;
+        unsafe {
+            engine.discard_opp_lwe_ciphertext_vector_unchecked(
+                &mut output_ciphertext_vector,
+                &input_ciphertext_vector,
+            )
+        };
+        (input_ciphertext_vector, output_ciphertext_vector)
+    }
+
+    fn process_context(
+        _parameters: &Self::Parameters,
+        maker: &mut Maker,
+        repetition_proto: &Self::RepetitionPrototypes,
+        sample_proto: &Self::SamplePrototypes,
+        context: Self::PostExecutionContext,
+    ) -> Self::Outcome {
+        let (input_ciphertext_vector, output_ciphertext_vector) = context;
+        let (proto_plaintext_vector, ..) = sample_proto;
+        let proto_secret_key = repetition_proto;
+        let raw_plaintext_vector =
+            maker.transform_plaintext_vector_to_raw_vec(proto_plaintext_vector);
+        let predicted_output = raw_plaintext_vector
+            .iter()
+            .map(|&a| a.wrapping_neg())
+            .collect();
+        let proto_output_ciphertext_vector =
+            maker.unsynthesize_lwe_ciphertext_vector(output_ciphertext_vector);
+        let proto_output_plaintext_vector = maker
+            .decrypt_lwe_ciphertext_vector_to_plaintext_vector(
+                proto_secret_key,
+                &proto_output_ciphertext_vector,
+            );
+        maker.destroy_lwe_ciphertext_vector(input_ciphertext_vector);
+        (
+            predicted_output,
+            maker.transform_plaintext_vector_to_raw_vec(&proto_output_plaintext_vector),
+        )
+    }
+
+    fn compute_criteria(
+        parameters: &Self::Parameters,
+        _maker: &mut Maker,
+        _repetition_proto: &Self::RepetitionPrototypes,
+    ) -> Self::Criteria {
+        (parameters.noise,)
+    }
+
+    fn verify(
+        _parameters: &Self::Parameters,
+        criteria: &Self::Criteria,
+        outputs: &[Self::Outcome],
+    ) -> bool {
+        let (means, actual): (Vec<_>, Vec<_>) = outputs.iter().cloned().unzip();
+        let means: Vec<Precision::Raw> = means.into_iter().flatten().collect();
+        let actual: Vec<Precision::Raw> = actual.into_iter().flatten().collect();
+        assert_noise_distribution(actual.as_slice(), means.as_slice(), criteria.0)
+    }
+}
diff --git a/concrete-core-fixture/src/fixture/mod.rs b/concrete-core-fixture/src/fixture/mod.rs
index f4b87bc6..6667fad5 100644
--- a/concrete-core-fixture/src/fixture/mod.rs
+++ b/concrete-core-fixture/src/fixture/mod.rs
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 //! A module containing a generic fixture trait for `concrete-core` operators.
 //!
 //! The central abstraction of the library is the [`Fixture`] trait. This trait defines the logic
@@ -361,6 +362,9 @@ pub use lwe_ciphertext_discarding_addition::*;
 mod lwe_ciphertext_discarding_opposite;
 pub use lwe_ciphertext_discarding_opposite::*;
 
+mod lwe_ciphertext_vector_discarding_opposite;
+pub use lwe_ciphertext_vector_discarding_opposite::*;
+
 mod lwe_ciphertext_fusing_addition;
 pub use lwe_ciphertext_fusing_addition::*;
 
diff --git a/concrete-core-test/src/cuda.rs b/concrete-core-test/src/cuda.rs
index 278c1fd6..f0685ea6 100644
--- a/concrete-core-test/src/cuda.rs
+++ b/concrete-core-test/src/cuda.rs
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 use crate::{REPETITIONS, SAMPLE_SIZE};
 use concrete_core::prelude::*;
 use concrete_core_fixture::fixture::*;
@@ -54,7 +55,12 @@ test! {
         CudaLweCiphertextVector, CudaLweCiphertextVector)),
     ((BinaryKeyDistribution, BinaryKeyDistribution), LweCiphertextVectorDiscardingBootstrapFixture2, (CudaFourierLweBootstrapKey,
         CudaGlweCiphertextVector,
-        CudaLweCiphertextVector, CudaLweCiphertextVector))
+        CudaLweCiphertextVector, CudaLweCiphertextVector)),
+    ((BinaryKeyDistribution),
+        LweCiphertextVectorDiscardingOppositeFixture, (CudaLweCiphertextVector,
+        CudaLweCiphertextVector)),
+    ((BinaryKeyDistribution),
+        LweCiphertextVectorDiscardingAdditionFixture, (CudaLweCiphertextVector, CudaLweCiphertextVector))
 }
 
 macro_rules! test_amortized {
diff --git a/concrete-core/README.md b/concrete-core/README.md
index d6d8433d..232bd83d 100644
--- a/concrete-core/README.md
+++ b/concrete-core/README.md
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 # Concrete Core
 
 This crate contains low-level implementations of homomorphic operators used in the
diff --git a/concrete-core/docs/README.md b/concrete-core/docs/README.md
index 2cf2ab9e..5284282a 100644
--- a/concrete-core/docs/README.md
+++ b/concrete-core/docs/README.md
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 # What is Concrete-core?
 
 ⭐️ [Star the repo on Github](https://github.com/zama-ai/Concrete-core) | 🗣 [Community support forum](https://community.zama.ai/c/concrete-lib) | 📁 [Contribute to the project](https://github.com/zama-ai/Concrete-core#contributing)
@@ -29,7 +30,7 @@ The library's design revolves around two modules:
 
 ## Rust documentation
 
-The [Rust documentation](https://docs.rs/concrete-core/1.0.0/concrete\_core) provides the full description of supported backends, data types and operations. For each implementation of an operation in a backend, an example of use is provided via a code snippet.
+The [Rust documentation](https://docs.rs/concrete-core/1.0.1/concrete\_core) provides the full description of supported backends, data types and operations. For each implementation of an operation in a backend, an example of use is provided via a code snippet.
 
 ## Activating backends
 
diff --git a/concrete-core/docs/SUMMARY.md b/concrete-core/docs/SUMMARY.md
index b4414709..0daabff3 100644
--- a/concrete-core/docs/SUMMARY.md
+++ b/concrete-core/docs/SUMMARY.md
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 # Table of contents
 
 * [What is Concrete-core?](README.md)
@@ -22,7 +23,7 @@
 
 ## API reference
 
-* [docs.rs](https://docs.rs/concrete-core/1.0.0/concrete\_core/index.html)
+* [docs.rs](https://docs.rs/concrete-core/1.0.1/concrete\_core/index.html)
 * [Using Concrete-core from C](api\_reference/concrete-core-ffi.md)
 * [Using Concrete-core from Javascript](api\_reference/concrete-core-wasm.md)
 
diff --git a/concrete-core/docs/backends/backend_cuda.md b/concrete-core/docs/backends/backend_cuda.md
index 6cfe05e6..d0af3226 100644
--- a/concrete-core/docs/backends/backend_cuda.md
+++ b/concrete-core/docs/backends/backend_cuda.md
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 # Cuda Backend
 
 This backend implements Cuda-accelerated versions of the bootstrap and the keyswitch over single inputs, or over vectors of inputs. It also implements conversion engines to be able to transfer data to the GPU and back to the CPU.
@@ -52,7 +53,7 @@ In this tutorial we'll see how to execute the Cuda-accelerated bootstrap over on
 In the `Cargo.toml` file, you just need to add `backend_cuda` to the features activated on `concrete-core`:
 
 ```shell
-concrete-core = {version = "=1.0.0", features=["backend_default", "backend_cuda", "backend_default_parallel"]}
+concrete-core = {version = "=1.0.1", features=["backend_default", "backend_cuda", "backend_default_parallel"]}
 ```
 
 Once again, let's begin by defining some cryptographic parameters (with no safety guarantee in the example, just like in the other tutorials) and inputs:
diff --git a/concrete-core/docs/backends/backend_default.md b/concrete-core/docs/backends/backend_default.md
index 69f9f1dd..75b8f78d 100644
--- a/concrete-core/docs/backends/backend_default.md
+++ b/concrete-core/docs/backends/backend_default.md
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 # Default Backend
 
 The default backend contains the CPU implementation of the majority of the engines from the specification. It is lightweight and very portable.
@@ -29,11 +30,11 @@ version = "0.1.0"
 edition = "2021"
 
 [dependencies]
-concrete-core = {version = "=1.0.0", features=["backend_default", "backend_default_parallel"]}
+concrete-core = {version = "=1.0.1", features=["backend_default", "backend_default_parallel"]}
 concrete-csprng = {version = "=0.2.1"}
 ```
 
-So we can use `concrete-core` version 1.0.0 as a dependency. Then, in the `main.rs` file ,we're going to:
+So we can use `concrete-core` version 1.0.1 as a dependency. Then, in the `main.rs` file ,we're going to:
 
 * import the necessary types and functions:
 
@@ -81,4 +82,4 @@ To execute this code, simply run:
 cargo run --release
 ```
 
-The full list of engines and entities implemented in the default backend is available in the [Rust documentation](https://docs.rs/concrete-core/1.0.0/concrete\_core/).
+The full list of engines and entities implemented in the default backend is available in the [Rust documentation](https://docs.rs/concrete-core/1.0.1/concrete\_core/).
diff --git a/concrete-core/docs/backends/backend_fft.md b/concrete-core/docs/backends/backend_fft.md
index 8299fb96..742bf704 100644
--- a/concrete-core/docs/backends/backend_fft.md
+++ b/concrete-core/docs/backends/backend_fft.md
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 # FFT Backend
 
 The FFT backend implements engines that require the transformation of polynomials from/to the Fourier domain. The Fourier conversions rely on a custom Rust FFT implementation, via a dependency to `concrete-fft`.
@@ -15,7 +16,7 @@ This backend supports any value for the polynomial size that is a power of 2. In
 In this tutorial, we'll see how to use the FFT backend to run a bootstrap and a keyswitch operation. In the `Cargo.toml` file, you just need to add `backend_fft` to the features activated on `concrete-core`:
 
 ```shell
-concrete-core = {version = "=1.0.0", features=["backend_default", "backend_fft", "backend_default_parallel"]}
+concrete-core = {version = "=1.0.1", features=["backend_default", "backend_fft", "backend_default_parallel"]}
 ```
 
 Just like in the default backend tutorial, we must first define some cryptographic parameters (that are unsecure and do not guarantee that the output is unaffected by the noise):
@@ -131,7 +132,7 @@ In this tutorial, we will see how to use the FFT backend to run the so-called wi
 In the `Cargo.toml` file, you need to add `backend_fft` to the features activated on `concrete-core`:
 
 ```toml
-concrete-core = {version = "=1.0.0", features=["backend_default", "backend_fft", "backend_default_parallel"]}
+concrete-core = {version = "=1.0.1", features=["backend_default", "backend_fft", "backend_default_parallel"]}
 ```
 
 The main difference between the PBS and wop PBS is that the latter operates over individual ciphertexts containing encrypted bits to evaluate a lookup table, while the former works on a single ciphertext encrypting a value over several bits.
diff --git a/concrete-core/docs/general_concepts/api_structure.md b/concrete-core/docs/general_concepts/api_structure.md
index ee785a51..6d88ab28 100644
--- a/concrete-core/docs/general_concepts/api_structure.md
+++ b/concrete-core/docs/general_concepts/api_structure.md
@@ -1,10 +1,11 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 # API Structure
 
 `concrete-core` is a modular library based on two main components:
 
 ![core\_architecture](../\_static/core.png)
 
-* The [`specification`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/index.html) module contains a blueprint (in the form of Rust Traits) of the FHE scheme exposed in `concrete-core`.
+* The [`specification`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/index.html) module contains a blueprint (in the form of Rust Traits) of the FHE scheme exposed in `concrete-core`.
 * The `backends` module contains submodules <mark style="background-color:yellow;">(such a submodule, we call a</mark> <mark style="background-color:yellow;"></mark>_<mark style="background-color:yellow;">backend</mark>_ <mark style="background-color:yellow;"></mark><mark style="background-color:yellow;">in this document)</mark>, which implement all or a part of the specification.
 
 Those backends may rely on different hardware resources, which may not always be available. For this reason, it is possible to include and exclude backends from a build by acting on the associated `backend_*` feature flag.
@@ -15,11 +16,11 @@ The `specification` module describes two kinds of objects which can be implement
 
 ### Entities.
 
-All the traits appearing in the [`specification::entities`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/entities/index.html) module represent the _datatypes_ manipulated in the library (we call _entities_ all these datatypes we use in the library). To mention a few of them, we have:
+All the traits appearing in the [`specification::entities`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/entities/index.html) module represent the _datatypes_ manipulated in the library (we call _entities_ all these datatypes we use in the library). To mention a few of them, we have:
 
-* [`PlaintextEntity`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/entities/trait.PlaintextEntity.html)
-* [`LweSecretKeyEntity`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/entities/trait.LweSecretKeyEntity.html)
-* [`LweCipertextEntity`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/entities/trait.LweCiphertextEntity.html)
+* [`PlaintextEntity`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/entities/trait.PlaintextEntity.html)
+* [`LweSecretKeyEntity`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/entities/trait.LweSecretKeyEntity.html)
+* [`LweCipertextEntity`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/entities/trait.LweCiphertextEntity.html)
 
 Only _one_ of the `*Entity` traits can be implemented at once, using a type exported by a backend. If a structure implements `PlaintextEntity`, it can not be `LweCiphertextEntity` at the same time, for instance. More details about the entities can be found [here](memory\_management.md).
 
@@ -27,11 +28,11 @@ Ciphertext entities have a `Vector` counterpart, that corresponds to an array of
 
 ### Engines.
 
-All the traits appearing in the [`specification::engines`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/index.html) module represent the _operators_ which can be used to manipulate entities in the library (we call _engines_ all these operators we use in the library). For instance, among others, we have:
+All the traits appearing in the [`specification::engines`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/index.html) module represent the _operators_ which can be used to manipulate entities in the library (we call _engines_ all these operators we use in the library). For instance, among others, we have:
 
-* [`LweSecretKeyGenerationEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweSecretKeyGenerationEngine.html)
-* [`LweCiphertextEncryptionEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweCiphertextEncryptionEngine.html)
-* [`LweCiphertextDecryptionEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweCiphertextDecryptionEngine.html)
+* [`LweSecretKeyGenerationEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweSecretKeyGenerationEngine.html)
+* [`LweCiphertextEncryptionEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweCiphertextEncryptionEngine.html)
+* [`LweCiphertextDecryptionEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweCiphertextDecryptionEngine.html)
 
 If you read between the lines, the fact that we use traits to represent operators means that we will have to use special objects (which we call _engines_ in this document) to perform the operations. This is slightly different from an object model in which operators are usually tied to the data themselves. In practice, this makes sense because we tend to use _side-resources_ to perform operations, and those are easier to handle when stored in a separate structure.
 
@@ -45,24 +46,24 @@ As mentioned earlier, backends contain the implementation of a subset of engines
 
 <mark style="background-color:yellow;">Four</mark> backends are available:
 
-* The default backend: contains Zama's own CPU-based implementation of the scheme. It is located at [`backends::default`](https://docs.rs/concrete-core/1.0.0/concrete\_core/backends/default/index.html) . The associated feature flag is the `backend_default`, but since it is the most prominent backend for now, we include it automatically (it is part of the `default` flag). It does not contain any hardware specific instructions unless configured otherwise. It is possible to configure it to activate x86\_64 specific acceleration for the encryption and creation of keys (with `aesni` and `rdseed` features). It also implements engines that accelerate some operations with multithreading (for now, the bootstrap key creation only). Finally, it also implements engines dedicated to serialization.
+* The default backend: contains Zama's own CPU-based implementation of the scheme. It is located at [`backends::default`](https://docs.rs/concrete-core/1.0.1/concrete\_core/backends/default/index.html) . The associated feature flag is the `backend_default`, but since it is the most prominent backend for now, we include it automatically (it is part of the `default` flag). It does not contain any hardware specific instructions unless configured otherwise. It is possible to configure it to activate x86\_64 specific acceleration for the encryption and creation of keys (with `aesni` and `rdseed` features). It also implements engines that accelerate some operations with multithreading (for now, the bootstrap key creation only). Finally, it also implements engines dedicated to serialization.
 * The FFT backend: implements engines that require an FFT implementation and relies on an in-house FFT implementation for it. For example, such operations are the bootstrap, the external product and the Cmux. It also implements operations to perform a large precision bootstrap (up to 16 bits) while relying on relatively small polynomial sizes.
 * The Cuda backend: exposes two Cuda accelerated implementations of the bootstrap, as well as a Cuda accelerated implementation of the keyswitch.
 
 In these backends, you will find the same structure as in the `specification`. Let's take the example of the default backend's structure (they all follow the same logic):
 
-* One [`engines`](https://docs.rs/concrete-core/1.0.0/concrete\_core/backends/default/engines/index.html) module containing the engines exported by the `default` backend
-* One [`entities`](https://docs.rs/concrete-core/1.0.0/concrete\_core/backends/default/entities/index.html) module containing the entities exported by the `default` backend
+* One [`engines`](https://docs.rs/concrete-core/1.0.1/concrete\_core/backends/default/engines/index.html) module containing the engines exported by the `default` backend
+* One [`entities`](https://docs.rs/concrete-core/1.0.1/concrete\_core/backends/default/entities/index.html) module containing the entities exported by the `default` backend
 
-In the `entities` module, among other types, we find the [`LweCiphertext64`](https://docs.rs/concrete-core/1.0.0/concrete\_core/backends/default/entities/struct.LweCiphertext64.html) type. It is an _entity_, which implements the [`LweCiphertextEntity`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/entities/trait.LweCiphertextEntity.html) trait (this type is actually listed in the implementors of the type).
+In the `entities` module, among other types, we find the [`LweCiphertext64`](https://docs.rs/concrete-core/1.0.1/concrete\_core/backends/default/entities/struct.LweCiphertext64.html) type. It is an _entity_, which implements the [`LweCiphertextEntity`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/entities/trait.LweCiphertextEntity.html) trait (this type is actually listed in the implementors of the type).
 
 In the `engines` module, we find three types:
 
-* [`DefaultEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/backends/default/engines/struct.DefaultEngine.html)
-* [`DefaultParallelEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/backends/default/engines/struct.DefaultParallelEngine.html)
-* [`DefaultSerializationEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/backends/default/engines/struct.DefaultSerializationEngine.html)
+* [`DefaultEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/backends/default/engines/struct.DefaultEngine.html)
+* [`DefaultParallelEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/backends/default/engines/struct.DefaultParallelEngine.html)
+* [`DefaultSerializationEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/backends/default/engines/struct.DefaultSerializationEngine.html)
 
-`DefaultEngine` is an _engine_ which implements many `*Engine` traits, among which the [`LweCiphertextEncryptionEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweCiphertextEncryptionEngine.html) trait, or the [`LweSecretKeyGenerationEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweSecretKeyGenerationEngine.html) trait, both of which are implemented for 32 and 64 bits precision.
+`DefaultEngine` is an _engine_ which implements many `*Engine` traits, among which the [`LweCiphertextEncryptionEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweCiphertextEncryptionEngine.html) trait, or the [`LweSecretKeyGenerationEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweSecretKeyGenerationEngine.html) trait, both of which are implemented for 32 and 64 bits precision.
 
 `DefaultParallelEngine`, on the other hand, implements only a subset of those, relying on multithreading to accelerate computations (via the `rayon` crate). This is particularly useful to accelerate the creation of bootstrap keys, for example.
 
@@ -78,22 +79,22 @@ As much as possible, we try to support different semantics for each operator in
 
 They take their inputs as arguments, allocate the objects holding the results and return them. We call them _pure_ in the sense of pure functions because they do not have side effects on entities (though they may have side effects on the engine). These engine traits do not have any particular prefixes in their names. When non-pure variants of the operator exist, the pure variant tends to require more resources because of the allocations it performs. Examples of such engine traits include:
 
-* [`LweCiphertextEncryptionEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweCiphertextEncryptionEngine.html)
-* [`LweBootstrapKeyGenerationEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweBootstrapKeyGenerationEngine.html)
+* [`LweCiphertextEncryptionEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweCiphertextEncryptionEngine.html)
+* [`LweBootstrapKeyGenerationEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweBootstrapKeyGenerationEngine.html)
 
 ### Discarding operators.
 
 They take both their inputs and outputs as arguments. In these operations, the data originally available in the outputs is not used for computation. We call them _discarding_ because they discard the data which exist in the output argument and replace it with something else. The engine traits following these semantics contain the `Discarding` word in their names. Examples of such engines traits include:
 
-* [`LweCiphertextDiscardingAdditionEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweCiphertextDiscardingAdditionEngine.html)
-* [`LweCiphertextDiscardingKeyswitchEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweCiphertextDiscardingKeyswitchEngine.html)
+* [`LweCiphertextDiscardingAdditionEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweCiphertextDiscardingAdditionEngine.html)
+* [`LweCiphertextDiscardingKeyswitchEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweCiphertextDiscardingKeyswitchEngine.html)
 
 ### Fusing operators.
 
 They take both their inputs and outputs as arguments. In these operations though, the data originally contained in the output is used for computation. We call them _fusing_ because they fuse input arguments into the output argument, which is used in the process (as opposed to _discarded_). The engine traits which follow these semantics contain the `Fusing` word in their names. Examples of such engines include:
 
-* [`LweCiphertextFusingAdditionEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweCiphertextFusingAdditionEngine.html)
-* [`LweCiphertextCleartextFusingMultiplicationEngine`](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweCiphertextCleartextFusingMultiplicationEngine.html)
+* [`LweCiphertextFusingAdditionEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweCiphertextFusingAdditionEngine.html)
+* [`LweCiphertextCleartextFusingMultiplicationEngine`](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweCiphertextCleartextFusingMultiplicationEngine.html)
 
 ## Error Management
 
diff --git a/concrete-core/docs/getting_started/quick_start.md b/concrete-core/docs/getting_started/quick_start.md
index 1f08c0a3..3db39bdd 100644
--- a/concrete-core/docs/getting_started/quick_start.md
+++ b/concrete-core/docs/getting_started/quick_start.md
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 # Quick Start
 
 Let's go over the example shown in the introduction, step by step. This example shows how to multiply a secret value by a public one, homomorphically.
@@ -25,9 +26,9 @@ Let's look at the `discard_mul_lwe_ciphertext_cleartext` operation: the dimensio
 "The input and output ciphertext LWE dimension must be the same."
 ```
 
-The list of supported errors for this operation is available [here](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/enum.LweCiphertextCleartextDiscardingMultiplicationError.html#variants), in the `Variants` section.
+The list of supported errors for this operation is available [here](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/enum.LweCiphertextCleartextDiscardingMultiplicationError.html#variants), in the `Variants` section.
 
-The full list of supported error types is available [here](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/#enums), in the `Enums` section.
+The full list of supported error types is available [here](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/#enums), in the `Enums` section.
 
 The errors managed by `Concrete-core` are checks regarding the compatibility of **cryptographic parameters**. <mark style="background-color:yellow;">There are no checks that when decrypting a ciphertext, the same secret key than the one used for encryption is used.</mark> This is left to the user to handle.
 
@@ -75,7 +76,7 @@ In order to use the `rdseed`-based seeder, you have to activate the feature flag
 
 The `engine` vocabulary is specific to `Concrete-core`. To make it short, the `DefaultEngine` is a type that can implement any number of `engine` traits that are supported in the library. Those traits correspond to cryptographic operations. More details about the architecture and vocabulary of `Concrete-core`'s API can be found [here](../general\_concepts/api\_structure.md).
 
-In what follows, the `engine` that was just created is going to be used to execute a number of cryptographic operations. The full list of operations implemented by the `DefaultEngine` is available [here](https://docs.rs/concrete-core/1.0.0/concrete\_core/backends/default/engines/struct.DefaultEngine.html), with code examples for each of them.
+In what follows, the `engine` that was just created is going to be used to execute a number of cryptographic operations. The full list of operations implemented by the `DefaultEngine` is available [here](https://docs.rs/concrete-core/1.0.1/concrete\_core/backends/default/engines/struct.DefaultEngine.html), with code examples for each of them.
 
 ### Input generation
 
@@ -87,7 +88,7 @@ Now that the `engine` has been created, let's head to the actual encryption stag
 
 Cleartexts are values of arbitrary type (unsigned integer, signed integer, float, structure, etc.) that are not meant to be encrypted but are used during the homomorphic computation. This wrapping was introduced in order to be able to bind the type of cleartext to the integer representation used for the ciphertext. In this case, the cleartext has to be represented with an unsigned integer with the same number of bits as what is used in the ciphertext, via the `Cleartext64` type.
 
-The full list of types implemented in the default backend is available [here](https://docs.rs/concrete-core/1.0.0/concrete\_core/backends/default/entities/index.html).
+The full list of types implemented in the default backend is available [here](https://docs.rs/concrete-core/1.0.1/concrete\_core/backends/default/entities/index.html).
 
 The encoded message itself is wrapped into a `Plaintext64` type. Plaintexts are unsigned integers that correspond **only** to an encoded message meant to be encrypted.
 
@@ -134,7 +135,7 @@ We can finally perform the multiplication, overwriting (discarding) the output c
     )?;
 ```
 
-The Rust documentation concerning this operation can be found [here](https://docs.rs/concrete-core/1.0.0/concrete\_core/backends/default/engines/struct.DefaultEngine.html#impl-LweCiphertextCleartextDiscardingMultiplicationEngine%3CLweCiphertext64%2C%20Cleartext64%2C%20LweCiphertext64%3E-for-DefaultEngine).
+The Rust documentation concerning this operation can be found [here](https://docs.rs/concrete-core/1.0.1/concrete\_core/backends/default/engines/struct.DefaultEngine.html#impl-LweCiphertextCleartextDiscardingMultiplicationEngine%3CLweCiphertext64%2C%20Cleartext64%2C%20LweCiphertext64%3E-for-DefaultEngine).
 
 ### Decryption
 
diff --git a/concrete-core/docs/getting_started/supported_data_types.md b/concrete-core/docs/getting_started/supported_data_types.md
index 66a40ec2..1c864efd 100644
--- a/concrete-core/docs/getting_started/supported_data_types.md
+++ b/concrete-core/docs/getting_started/supported_data_types.md
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 # Supported Data Types
 
 The FHE data types supported by Concrete-core belong to several categories, described below.
@@ -36,6 +37,6 @@ Two types of non-encrypted data are exposed in the form of types in the API (asi
 
 ## Full list of supported types
 
-The full list of supported data types in `Concrete-core` is available in the [specification page](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/entities/index.html#traits) of the Rust documentation. The cryptographic content of each type is described in the Rust documentation itself. For example, the description of the keyswitch key can be found [here](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/entities/trait.LweKeyswitchKeyEntity.html).
+The full list of supported data types in `Concrete-core` is available in the [specification page](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/entities/index.html#traits) of the Rust documentation. The cryptographic content of each type is described in the Rust documentation itself. For example, the description of the keyswitch key can be found [here](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/entities/trait.LweKeyswitchKeyEntity.html).
 
 Head out to the page about [supported operations](supported\_operations.md) to get to know them.
diff --git a/concrete-core/docs/getting_started/supported_operations.md b/concrete-core/docs/getting_started/supported_operations.md
index ec50c63d..311c2de5 100644
--- a/concrete-core/docs/getting_started/supported_operations.md
+++ b/concrete-core/docs/getting_started/supported_operations.md
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 # Supported Operations
 
 These operations belong to several categories, described below.
@@ -14,7 +15,7 @@ Other basic operations are the transformation of an LWE secret key into a GLWE s
 
 ## Bootstrapping
 
-`Concrete-core` supports a number of operations related to TFHE's programmable bootstrap: the programmable bootstrap itself, the Cmux, the external product, the circuit bootstrap (that transforms an LWE ciphertext into a GGSW ciphertext), the vertical packing, and the bit extraction. The cryptographic description of each of these can be found in the Rust documentation itself (see the [bootstrap](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweCiphertextDiscardingBootstrapEngine.html#formal-definition)).
+`Concrete-core` supports a number of operations related to TFHE's programmable bootstrap: the programmable bootstrap itself, the Cmux, the external product, the circuit bootstrap (that transforms an LWE ciphertext into a GGSW ciphertext), the vertical packing, and the bit extraction. The cryptographic description of each of these can be found in the Rust documentation itself (see the [bootstrap](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweCiphertextDiscardingBootstrapEngine.html#formal-definition)).
 
 ## Data management
 
@@ -22,4 +23,4 @@ Finally, a number of operations in `Concrete-core` help with data management. Fo
 
 ## Full list of operations
 
-The full list of supported operations in `Concrete-core` is available in the [specification page](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/index.html#traits) of the Rust documentation. The cryptographic content of each operation is described in a `Formal definition` in the Rust documentation itself. For example, the description of the keyswitch can be found [here](https://docs.rs/concrete-core/1.0.0/concrete\_core/specification/engines/trait.LweCiphertextDiscardingKeyswitchEngine.html#formal-definition). A code snippet for each implementation of these operations in the various supported backends is available in the Rust documentation.
+The full list of supported operations in `Concrete-core` is available in the [specification page](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/index.html#traits) of the Rust documentation. The cryptographic content of each operation is described in a `Formal definition` in the Rust documentation itself. For example, the description of the keyswitch can be found [here](https://docs.rs/concrete-core/1.0.1/concrete\_core/specification/engines/trait.LweCiphertextDiscardingKeyswitchEngine.html#formal-definition). A code snippet for each implementation of these operations in the various supported backends is available in the Rust documentation.
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_amortized_engine/lwe_ciphertext_vector_k_discarding_bootstrap.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_amortized_engine/lwe_ciphertext_vector_k_discarding_bootstrap.rs
new file mode 100644
index 00000000..a3b7df90
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_amortized_engine/lwe_ciphertext_vector_k_discarding_bootstrap.rs
@@ -0,0 +1,61 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::engines::CudaError;
+use crate::backends::cuda::implementation::engines::{
+    AmortizedCudaEngine,
+};
+use crate::backends::cuda::implementation::entities::{
+    CudaFourierLweBootstrapKey64,
+    CudaGlweCiphertextVector64, CudaLweCiphertextVector64,
+};
+use crate::backends::cuda::private::crypto::bootstrap::execute_lwe_ciphertext_vector_k_amortized_bootstrap_on_gpu;
+use crate::specification::engines::{
+    LweCiphertextVectorKDiscardingBootstrapEngine, LweCiphertextVectorKDiscardingBootstrapError,
+};
+use crate::specification::entities::LweBootstrapKeyEntity;
+
+impl
+    LweCiphertextVectorKDiscardingBootstrapEngine<
+        CudaFourierLweBootstrapKey64,
+        CudaGlweCiphertextVector64,
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for AmortizedCudaEngine
+{
+    fn discard_bootstrap_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+        acc: &CudaGlweCiphertextVector64,
+        bsk: &CudaFourierLweBootstrapKey64,
+        k: usize,
+    ) -> Result<(), LweCiphertextVectorKDiscardingBootstrapError<CudaError>> {
+        LweCiphertextVectorKDiscardingBootstrapError::perform_generic_checks(
+            output, input, acc, bsk,
+        )?;
+        let _poly_size = bsk.polynomial_size().0;
+        let _glwe_dim = bsk.glwe_dimension();
+        let _base_log = bsk.decomposition_base_log();
+        unsafe { self.discard_bootstrap_lwe_ciphertext_vector_k_unchecked(output, input, acc, bsk, k) };
+        Ok(())
+    }
+
+    unsafe fn discard_bootstrap_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+        acc: &CudaGlweCiphertextVector64,
+        bsk: &CudaFourierLweBootstrapKey64,
+        k: usize,
+    ) {
+        execute_lwe_ciphertext_vector_k_amortized_bootstrap_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input.0,
+            &acc.0,
+            &bsk.0,
+            k,
+            self.get_number_of_gpus(),
+            self.get_cuda_shared_memory(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_amortized_engine/mod.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_amortized_engine/mod.rs
index fd4d564b..76b6b4d3 100644
--- a/concrete-core/src/backends/cuda/implementation/engines/cuda_amortized_engine/mod.rs
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_amortized_engine/mod.rs
@@ -70,3 +70,4 @@ macro_rules! check_poly_size {
 }
 
 mod lwe_ciphertext_vector_discarding_bootstrap;
+mod lwe_ciphertext_vector_k_discarding_bootstrap; // This function was newly added by the authors of cuparmesan
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_discarding_addition.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_discarding_addition.rs
new file mode 100644
index 00000000..7ce11def
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_discarding_addition.rs
@@ -0,0 +1,72 @@
+// This file was newly added by the authors of cuparmesan
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertext32, CudaLweCiphertext64,
+    LweCiphertextDiscardingAdditionEngine, LweCiphertextDiscardingAdditionError,
+};
+use crate::backends::cuda::private::device::NumberOfSamples;
+
+impl
+    LweCiphertextDiscardingAdditionEngine<
+        CudaLweCiphertext32,
+        CudaLweCiphertext32,
+    > for CudaEngine
+{
+    fn discard_add_lwe_ciphertext(
+        &mut self,
+        output: &mut CudaLweCiphertext32,
+        input_1: &CudaLweCiphertext32,
+        input_2: &CudaLweCiphertext32,
+    ) -> Result<(), LweCiphertextDiscardingAdditionError<Self::EngineError>> {
+        unsafe { self.discard_add_lwe_ciphertext_unchecked(output, input_1, input_2) };
+        Ok(())
+    }
+
+    unsafe fn discard_add_lwe_ciphertext_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertext32,
+        input_1: &CudaLweCiphertext32,
+        input_2: &CudaLweCiphertext32,
+    ) {
+        let stream = &self.streams[0];
+        stream.discard_add_lwe_ciphertext_vector::<u32>(
+            &mut output.0.d_vec,
+            &input_1.0.d_vec,
+            &input_2.0.d_vec,
+            input_1.0.lwe_dimension,
+            NumberOfSamples(1),
+        );
+    }
+}
+
+impl
+    LweCiphertextDiscardingAdditionEngine<
+        CudaLweCiphertext64,
+        CudaLweCiphertext64,
+    > for CudaEngine
+{
+    fn discard_add_lwe_ciphertext(
+        &mut self,
+        output: &mut CudaLweCiphertext64,
+        input_1: &CudaLweCiphertext64,
+        input_2: &CudaLweCiphertext64,
+    ) -> Result<(), LweCiphertextDiscardingAdditionError<Self::EngineError>> {
+        unsafe { self.discard_add_lwe_ciphertext_unchecked(output, input_1, input_2) };
+        Ok(())
+    }
+
+    unsafe fn discard_add_lwe_ciphertext_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertext64,
+        input_1: &CudaLweCiphertext64,
+        input_2: &CudaLweCiphertext64,
+    ) {
+        let stream = &self.streams[0];
+        stream.discard_add_lwe_ciphertext_vector::<u64>(
+            &mut output.0.d_vec,
+            &input_1.0.d_vec,
+            &input_2.0.d_vec,
+            input_1.0.lwe_dimension,
+            NumberOfSamples(1),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_addition.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_addition.rs
new file mode 100644
index 00000000..ef443ce1
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_addition.rs
@@ -0,0 +1,72 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
+use crate::backends::cuda::private::crypto::lwe::list::{execute_lwe_ciphertext_vector_addition_on_gpu};
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector32, CudaLweCiphertextVector64,
+    LweCiphertextVectorDiscardingAdditionEngine, LweCiphertextVectorDiscardingAdditionError,
+};
+
+// This function was modified by the authors of cuparmesan
+impl
+    LweCiphertextVectorDiscardingAdditionEngine<
+        CudaLweCiphertextVector32,
+        CudaLweCiphertextVector32,
+    > for CudaEngine
+{
+    fn discard_add_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector32,
+        input_1: &CudaLweCiphertextVector32,
+        input_2: &CudaLweCiphertextVector32,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionError<Self::EngineError>> {
+        unsafe { self.discard_add_lwe_ciphertext_vector_unchecked(output, input_1, input_2) };
+        Ok(())
+    }
+
+    unsafe fn discard_add_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector32,
+        input_1: &CudaLweCiphertextVector32,
+        input_2: &CudaLweCiphertextVector32,
+    ) {
+        execute_lwe_ciphertext_vector_addition_on_gpu::<u32>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            &input_2.0,
+            self.get_number_of_gpus(),
+        );
+    }
+}
+
+// This function was modified by the authors of cuparmesan
+impl
+    LweCiphertextVectorDiscardingAdditionEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_add_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionError<Self::EngineError>> {
+        unsafe { self.discard_add_lwe_ciphertext_vector_unchecked(output, input_1, input_2) };
+        Ok(())
+    }
+
+    unsafe fn discard_add_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+    ) {
+        execute_lwe_ciphertext_vector_addition_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            &input_2.0,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_addition_local.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_addition_local.rs
new file mode 100644
index 00000000..96f5ba27
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_addition_local.rs
@@ -0,0 +1,162 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::private::crypto::lwe::list::{execute_lwe_ciphertext_vector_add_to_local_on_gpu, execute_lwe_ciphertext_vector_x_plus_2y_to_local_on_gpu, execute_lwe_ciphertext_vector_sftadd_from_local_on_gpu, execute_lwe_ciphertext_vector_copy_from_local_on_gpu,execute_lwe_ciphertext_vector_copy_from_local_for_sign_on_gpu};
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector64,
+    LweCiphertextVectorDiscardingAdditionLocalEngine, LweCiphertextVectorDiscardingAdditionLocalError,
+};
+
+impl
+    LweCiphertextVectorDiscardingAdditionLocalEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+
+    fn discard_add_to_local_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        i: u32,
+        d: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionLocalError<Self::EngineError>> {
+        unsafe { self.discard_add_to_local_lwe_ciphertext_vector_unchecked(output, input_1, i, d) };
+        Ok(())
+    }
+
+    unsafe fn discard_add_to_local_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        i: u32,
+        d: u32,
+    ) {
+        execute_lwe_ciphertext_vector_add_to_local_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            i,
+            d,
+            self.get_number_of_gpus(),
+        );
+    }
+
+    fn discard_x_plus_2y_to_local_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        i: u32,
+        d: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionLocalError<Self::EngineError>> {
+        unsafe { self.discard_x_plus_2y_to_local_lwe_ciphertext_vector_unchecked(output, input_1, i, d) };
+        Ok(())
+    }
+
+    unsafe fn discard_x_plus_2y_to_local_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        i: u32,
+        d: u32,
+    ) {
+        execute_lwe_ciphertext_vector_x_plus_2y_to_local_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            i,
+            d,
+            self.get_number_of_gpus(),
+        );
+    }
+
+
+
+    fn discard_sftadd_from_local_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+        i: u32,
+        d: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionLocalError<Self::EngineError>> {
+        unsafe { self.discard_sftadd_from_local_lwe_ciphertext_vector_unchecked(output, input_1, input_2, i, d) };
+        Ok(())
+    }
+
+    unsafe fn discard_sftadd_from_local_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+        i: u32,
+        d: u32,
+    ) {
+        execute_lwe_ciphertext_vector_sftadd_from_local_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            &input_2.0,
+            i,
+            d,
+            self.get_number_of_gpus(),
+        );
+    }
+
+    fn discard_copy_from_local_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        i: u32,
+        d: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionLocalError<Self::EngineError>> {
+        unsafe { self.discard_copy_from_local_lwe_ciphertext_vector_unchecked(output, input_1, i, d) };
+        Ok(())
+    }
+
+    unsafe fn discard_copy_from_local_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        i: u32,
+        d: u32,
+    ) {
+        execute_lwe_ciphertext_vector_copy_from_local_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            i,
+            d,
+            self.get_number_of_gpus(),
+        );
+    }
+
+    fn discard_copy_from_local_for_sign_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        i: u32,
+        d: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionLocalError<Self::EngineError>> {
+        // LweCiphertextVectorDiscardingAdditionLocalError::perform_generic_checks(
+        //     output, input_1, input_2,
+        // )?;
+        unsafe { self.discard_copy_from_local_for_sign_lwe_ciphertext_vector_unchecked(output, input_1, i, d) };
+        Ok(())
+    }
+
+    unsafe fn discard_copy_from_local_for_sign_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        i: u32,
+        d: u32,
+    ) {
+        execute_lwe_ciphertext_vector_copy_from_local_for_sign_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            i,
+            d,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_and.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_and.rs
new file mode 100644
index 00000000..e268fa4a
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_and.rs
@@ -0,0 +1,38 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::private::crypto::lwe::list::execute_lwe_ciphertext_vector_and_on_gpu;
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector64,
+    LweCiphertextVectorDiscardingAndEngine, LweCiphertextVectorDiscardingAndError,
+};
+
+impl
+    LweCiphertextVectorDiscardingAndEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_and_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+    ) -> Result<(), LweCiphertextVectorDiscardingAndError<Self::EngineError>> {
+        unsafe { self.discard_and_lwe_ciphertext_vector_unchecked(output, input_1, input_2) };
+        Ok(())
+    }
+
+    unsafe fn discard_and_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+    ) {
+        execute_lwe_ciphertext_vector_and_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            &input_2.0,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_copy_at.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_copy_at.rs
new file mode 100644
index 00000000..cb5d73be
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_copy_at.rs
@@ -0,0 +1,89 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::private::crypto::lwe::list::{execute_lwe_ciphertext_vector_copy_at_on_gpu, execute_lwe_ciphertext_vector_copy_n_at_on_gpu, execute_lwe_ciphertext_vector_set_at_on_gpu};
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector64,
+    LweCiphertextVectorDiscardingCopyAtEngine, LweCiphertextVectorDiscardingCopyAtError, // TODO: impl
+};
+
+
+impl
+    LweCiphertextVectorDiscardingCopyAtEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_copy_at_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingCopyAtError<Self::EngineError>> {
+        unsafe { self.discard_copy_at_lwe_ciphertext_vector_unchecked(output, input_1, k) };
+        Ok(())
+    }
+
+    unsafe fn discard_copy_at_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32,
+    ) {
+        execute_lwe_ciphertext_vector_copy_at_on_gpu::<u64>( // @
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            k,
+            self.get_number_of_gpus(),
+        );
+    }
+
+    fn discard_copy_n_at_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingCopyAtError<Self::EngineError>> {
+        unsafe { self.discard_copy_n_at_lwe_ciphertext_vector_unchecked(output, input_1, k) };
+        Ok(())
+    }
+
+    unsafe fn discard_copy_n_at_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32,
+    ) {
+        execute_lwe_ciphertext_vector_copy_n_at_on_gpu::<u64>( // @
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            k,
+            self.get_number_of_gpus(),
+        );
+    }
+
+    fn discard_set_at_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingCopyAtError<Self::EngineError>> {
+        unsafe { self.discard_set_at_lwe_ciphertext_vector_unchecked(output, input_1, k) };
+        Ok(())
+    }
+
+    unsafe fn discard_set_at_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32,
+    ) {
+        execute_lwe_ciphertext_vector_set_at_on_gpu::<u64>( // @
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            k,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_max.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_max.rs
new file mode 100644
index 00000000..48abdef1
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_max.rs
@@ -0,0 +1,64 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::private::crypto::lwe::list::{execute_lwe_ciphertext_vector_merge_xy_on_gpu, execute_lwe_ciphertext_vector_extend_xy_on_gpu};
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector64,
+    LweCiphertextVectorDiscardingMaxEngine, LweCiphertextVectorDiscardingMaxError,
+};
+
+
+impl
+    LweCiphertextVectorDiscardingMaxEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_extend_xy_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+        input_3: &CudaLweCiphertextVector64,
+    ) -> Result<(), LweCiphertextVectorDiscardingMaxError<Self::EngineError>> {
+        unsafe { self.discard_extend_xy_lwe_ciphertext_vector_unchecked(output, input_1, input_2, input_3) };
+        Ok(())
+    }
+
+    unsafe fn discard_extend_xy_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+        input_3: &CudaLweCiphertextVector64,
+    ) {
+        execute_lwe_ciphertext_vector_extend_xy_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            &input_2.0,
+            &input_3.0,
+            self.get_number_of_gpus(),
+        );
+    }
+
+    fn discard_merge_xy_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+    ) -> Result<(), LweCiphertextVectorDiscardingMaxError<Self::EngineError>> {
+        unsafe { self.discard_merge_xy_lwe_ciphertext_vector_unchecked(output, input) };
+        Ok(())
+    }
+
+    unsafe fn discard_merge_xy_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+    ) {
+        execute_lwe_ciphertext_vector_merge_xy_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input.0,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_multbyconst.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_multbyconst.rs
new file mode 100644
index 00000000..0d0adb11
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_multbyconst.rs
@@ -0,0 +1,67 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::private::crypto::lwe::list::{execute_lwe_ciphertext_vector_mult_by_const_on_gpu, execute_lwe_ciphertext_vector_k_mult_by_const_on_gpu};
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector64,
+    LweCiphertextVectorDiscardingMultByConstEngine, LweCiphertextVectorDiscardingMultByConstError,
+};
+
+
+impl
+    LweCiphertextVectorDiscardingMultByConstEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_mult_by_const_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingMultByConstError<Self::EngineError>> {
+        unsafe { self.discard_mult_by_const_lwe_ciphertext_vector_unchecked(output, input_1, k) };
+        Ok(())
+    }
+
+    unsafe fn discard_mult_by_const_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32,
+    ) {
+        execute_lwe_ciphertext_vector_mult_by_const_on_gpu::<u64>( // @
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            k,
+            self.get_number_of_gpus(),
+        );
+    }
+
+    fn discard_mult_by_const_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32,
+        k2: usize,
+    ) -> Result<(), LweCiphertextVectorDiscardingMultByConstError<Self::EngineError>> {
+        unsafe { self.discard_mult_by_const_lwe_ciphertext_vector_k_unchecked(output, input_1, k, k2) };
+        Ok(())
+    }
+
+    unsafe fn discard_mult_by_const_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32,
+        k2: usize,
+    ) {
+        execute_lwe_ciphertext_vector_k_mult_by_const_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            k,
+            k2,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_opposite.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_opposite.rs
new file mode 100644
index 00000000..0ece97ed
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_opposite.rs
@@ -0,0 +1,66 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
+use crate::backends::cuda::private::crypto::lwe::list::execute_lwe_ciphertext_vector_opposite_on_gpu;
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector32, CudaLweCiphertextVector64,
+    LweCiphertextVectorDiscardingOppositeEngine, LweCiphertextVectorDiscardingOppositeError,
+};
+
+impl
+    LweCiphertextVectorDiscardingOppositeEngine<
+        CudaLweCiphertextVector32,
+        CudaLweCiphertextVector32,
+    > for CudaEngine
+{
+    fn discard_opp_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector32,
+        input: &CudaLweCiphertextVector32,
+    ) -> Result<(), LweCiphertextVectorDiscardingOppositeError<Self::EngineError>> {
+        LweCiphertextVectorDiscardingOppositeError::perform_generic_checks(output, input)?;
+        unsafe { self.discard_opp_lwe_ciphertext_vector_unchecked(output, input) };
+        Ok(())
+    }
+
+    unsafe fn discard_opp_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector32,
+        input: &CudaLweCiphertextVector32,
+    ) {
+        execute_lwe_ciphertext_vector_opposite_on_gpu::<u32>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input.0,
+            self.get_number_of_gpus(),
+        );
+    }
+}
+
+impl
+    LweCiphertextVectorDiscardingOppositeEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_opp_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+    ) -> Result<(), LweCiphertextVectorDiscardingOppositeError<Self::EngineError>> {
+        LweCiphertextVectorDiscardingOppositeError::perform_generic_checks(output, input)?;
+        unsafe { self.discard_opp_lwe_ciphertext_vector_unchecked(output, input) };
+        Ok(())
+    }
+
+    unsafe fn discard_opp_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+    ) {
+        execute_lwe_ciphertext_vector_opposite_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input.0,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_opposite_inplace.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_opposite_inplace.rs
new file mode 100644
index 00000000..4c97defa
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_opposite_inplace.rs
@@ -0,0 +1,55 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::private::crypto::lwe::list::{execute_lwe_ciphertext_vector_opposite_on_gpu_inplace,execute_lwe_ciphertext_vector_k_opposite_on_gpu_inplace};
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector64,
+    LweCiphertextVectorDiscardingOppositeInplaceEngine, LweCiphertextVectorDiscardingOppositeInplaceError,
+};
+
+
+impl
+    LweCiphertextVectorDiscardingOppositeInplaceEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_opp_lwe_ciphertext_vector_inplace(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+    ) -> Result<(), LweCiphertextVectorDiscardingOppositeInplaceError<Self::EngineError>> {
+        unsafe { self.discard_opp_lwe_ciphertext_vector_inplace_unchecked(output) };
+        Ok(())
+    }
+
+    unsafe fn discard_opp_lwe_ciphertext_vector_inplace_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+    ) {
+        execute_lwe_ciphertext_vector_opposite_on_gpu_inplace::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            self.get_number_of_gpus(),
+        );
+    }
+
+    fn discard_opp_lwe_ciphertext_vector_k_inplace(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        k: usize
+    ) -> Result<(), LweCiphertextVectorDiscardingOppositeInplaceError<Self::EngineError>> {
+        unsafe { self.discard_opp_lwe_ciphertext_vector_k_inplace_unchecked(output,k) };
+        Ok(())
+    }
+
+    unsafe fn discard_opp_lwe_ciphertext_vector_k_inplace_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        k: usize
+    ) {
+        execute_lwe_ciphertext_vector_k_opposite_on_gpu_inplace::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            k,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_rotation.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_rotation.rs
new file mode 100644
index 00000000..7ba88dc0
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_rotation.rs
@@ -0,0 +1,39 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::private::crypto::lwe::list::execute_lwe_ciphertext_vector_rotation_on_gpu;
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector64,
+    LweCiphertextVectorDiscardingRotationEngine, LweCiphertextVectorDiscardingRotationError,
+};
+
+impl
+    LweCiphertextVectorDiscardingRotationEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_rotate_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingRotationError<Self::EngineError>> {
+        LweCiphertextVectorDiscardingRotationError::perform_generic_checks(output, input)?;
+        unsafe { self.discard_rotate_lwe_ciphertext_vector_unchecked(output, input, k) };
+        Ok(())
+    }
+
+    unsafe fn discard_rotate_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+        k: u32,
+    ) {
+        execute_lwe_ciphertext_vector_rotation_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input.0,
+            k,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_rotation_all.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_rotation_all.rs
new file mode 100644
index 00000000..b3e1f669
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_rotation_all.rs
@@ -0,0 +1,36 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::private::crypto::lwe::list::execute_lwe_ciphertext_vector_rotation_all_on_gpu;
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector64,
+    LweCiphertextVectorDiscardingRotationAllEngine, LweCiphertextVectorDiscardingRotationAllError,
+};
+
+
+impl
+    LweCiphertextVectorDiscardingRotationAllEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_rotate_all_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+    ) -> Result<(), LweCiphertextVectorDiscardingRotationAllError<Self::EngineError>> {
+        unsafe { self.discard_rotate_all_lwe_ciphertext_vector_unchecked(output, input) };
+        Ok(())
+    }
+
+    unsafe fn discard_rotate_all_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+    ) {
+        execute_lwe_ciphertext_vector_rotation_all_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input.0,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_shiftaddition.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_shiftaddition.rs
new file mode 100644
index 00000000..f5fcfb79
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_discarding_shiftaddition.rs
@@ -0,0 +1,92 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::private::crypto::lwe::list::{execute_lwe_ciphertext_vector_shiftaddition_on_gpu,execute_lwe_ciphertext_vector_shiftaddition_k_on_gpu,execute_lwe_ciphertext_vector_shiftaddition_k_on_gpu_inplace}; // narisada
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector64,
+    LweCiphertextVectorDiscardingShiftAdditionEngine, LweCiphertextVectorDiscardingShiftAdditionError,
+};
+
+impl
+    LweCiphertextVectorDiscardingShiftAdditionEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_sftadd_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+    ) -> Result<(), LweCiphertextVectorDiscardingShiftAdditionError<Self::EngineError>> {
+        unsafe { self.discard_sftadd_lwe_ciphertext_vector_unchecked(output, input_1, input_2) };
+        Ok(())
+    }
+
+    unsafe fn discard_sftadd_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+    ) {
+        execute_lwe_ciphertext_vector_shiftaddition_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            &input_2.0,
+            self.get_number_of_gpus(),
+        );
+    }
+
+    fn discard_sftadd_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingShiftAdditionError<Self::EngineError>> {
+        unsafe { self.discard_sftadd_lwe_ciphertext_vector_k_unchecked(output, input_1, input_2, k ) };
+        Ok(())
+    }
+
+    unsafe fn discard_sftadd_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+        k: u32
+    ) {
+        execute_lwe_ciphertext_vector_shiftaddition_k_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            &input_2.0,
+            k,
+            self.get_number_of_gpus(),
+        );
+    }
+
+    fn inplace_sftadd_lwe_ciphertext_vector_k( //
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingShiftAdditionError<Self::EngineError>> {
+        unsafe { self.inplace_sftadd_lwe_ciphertext_vector_k_unchecked(output, input_1, k ) };
+        Ok(())
+    }
+
+    unsafe fn inplace_sftadd_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        k: u32
+    ) {
+        execute_lwe_ciphertext_vector_shiftaddition_k_on_gpu_inplace::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            k,
+            self.get_number_of_gpus(),
+        );
+    }
+
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_fusing_addition.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_fusing_addition.rs
new file mode 100644
index 00000000..2dcc80da
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_fusing_addition.rs
@@ -0,0 +1,65 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::private::crypto::lwe::list::{execute_lwe_ciphertext_vector_addition_inplace_on_gpu};
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector32, CudaLweCiphertextVector64,
+    LweCiphertextVectorFusingAdditionEngine, LweCiphertextVectorFusingAdditionError,
+};
+
+impl
+    LweCiphertextVectorFusingAdditionEngine<
+        CudaLweCiphertextVector32,
+        CudaLweCiphertextVector32,
+    > for CudaEngine
+{
+    fn fuse_add_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector32,
+        input: &CudaLweCiphertextVector32,
+    ) -> Result<(), LweCiphertextVectorFusingAdditionError<Self::EngineError>> {
+        unsafe { self.fuse_add_lwe_ciphertext_vector_unchecked(output, input) };
+        Ok(())
+    }
+
+    unsafe fn fuse_add_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector32,
+        input: &CudaLweCiphertextVector32,
+    ) {
+        execute_lwe_ciphertext_vector_addition_inplace_on_gpu::<u32>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input.0,
+            self.get_number_of_gpus(),
+        );
+    }
+}
+
+impl
+    LweCiphertextVectorFusingAdditionEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn fuse_add_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+    ) -> Result<(), LweCiphertextVectorFusingAdditionError<Self::EngineError>> {
+        unsafe { self.fuse_add_lwe_ciphertext_vector_unchecked(output, input) };
+        Ok(())
+    }
+
+    unsafe fn fuse_add_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+    ) {
+        execute_lwe_ciphertext_vector_addition_inplace_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input.0,
+            self.get_number_of_gpus(),
+        );
+    }
+
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_k_discarding_addition.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_k_discarding_addition.rs
new file mode 100644
index 00000000..f9495e97
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_k_discarding_addition.rs
@@ -0,0 +1,83 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::private::crypto::lwe::list::execute_lwe_ciphertext_vector_k_addition_on_gpu;
+use crate::prelude::{
+    CudaEngine, CudaLweCiphertextVector32, CudaLweCiphertextVector64,
+    LweCiphertextVectorKDiscardingAdditionEngine, LweCiphertextVectorKDiscardingAdditionError,
+};
+
+impl
+    LweCiphertextVectorKDiscardingAdditionEngine<
+        CudaLweCiphertextVector32,
+        CudaLweCiphertextVector32,
+    > for CudaEngine
+{
+    fn discard_add_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut CudaLweCiphertextVector32,
+        input_1: &CudaLweCiphertextVector32,
+        input_2: &CudaLweCiphertextVector32,
+        k: usize,
+    ) -> Result<(), LweCiphertextVectorKDiscardingAdditionError<Self::EngineError>> {
+        LweCiphertextVectorKDiscardingAdditionError::perform_generic_checks(
+            output, input_1, input_2,
+        )?;
+        unsafe { self.discard_add_lwe_ciphertext_vector_k_unchecked(output, input_1, input_2, k) };
+        Ok(())
+    }
+
+    unsafe fn discard_add_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector32,
+        input_1: &CudaLweCiphertextVector32,
+        input_2: &CudaLweCiphertextVector32,
+        k: usize,
+    ) {
+        execute_lwe_ciphertext_vector_k_addition_on_gpu::<u32>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            &input_2.0,
+            k,
+            self.get_number_of_gpus(),
+        );
+    }
+
+}
+
+impl
+    LweCiphertextVectorKDiscardingAdditionEngine<
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_add_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+        k: usize,
+    ) -> Result<(), LweCiphertextVectorKDiscardingAdditionError<Self::EngineError>> {
+        LweCiphertextVectorKDiscardingAdditionError::perform_generic_checks(
+            output, input_1, input_2,
+        )?;
+        unsafe { self.discard_add_lwe_ciphertext_vector_k_unchecked(output, input_1, input_2, k) };
+        Ok(())
+    }
+
+    unsafe fn discard_add_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input_1: &CudaLweCiphertextVector64,
+        input_2: &CudaLweCiphertextVector64,
+        k: usize,
+    ) {
+        execute_lwe_ciphertext_vector_k_addition_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input_1.0,
+            &input_2.0,
+            k,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_k_discarding_keyswitch.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_k_discarding_keyswitch.rs
new file mode 100644
index 00000000..13a82ca1
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_k_discarding_keyswitch.rs
@@ -0,0 +1,54 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::engines::CudaError;
+use crate::backends::cuda::implementation::engines::CudaEngine;
+use crate::backends::cuda::implementation::entities::{
+    CudaLweCiphertextVector64,
+    CudaLweKeyswitchKey64,
+};
+use crate::backends::cuda::private::crypto::keyswitch::execute_lwe_ciphertext_vector_k_keyswitch_on_gpu;
+use crate::specification::engines::{
+    LweCiphertextVectorKDiscardingKeyswitchEngine, LweCiphertextVectorKDiscardingKeyswitchError,
+};
+
+impl From<CudaError> for LweCiphertextVectorKDiscardingKeyswitchError<CudaError> {
+    fn from(err: CudaError) -> Self {
+        Self::Engine(err)
+    }
+}
+
+impl
+    LweCiphertextVectorKDiscardingKeyswitchEngine<
+        CudaLweKeyswitchKey64,
+        CudaLweCiphertextVector64,
+        CudaLweCiphertextVector64,
+    > for CudaEngine
+{
+    fn discard_keyswitch_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+        ksk: &CudaLweKeyswitchKey64,
+        k: usize,
+    ) -> Result<(), LweCiphertextVectorKDiscardingKeyswitchError<CudaError>> {
+        LweCiphertextVectorKDiscardingKeyswitchError::perform_generic_checks(output, input, ksk)?;
+        unsafe { self.discard_keyswitch_lwe_ciphertext_vector_k_unchecked(output, input, ksk, k) };
+        Ok(())
+    }
+
+    unsafe fn discard_keyswitch_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut CudaLweCiphertextVector64,
+        input: &CudaLweCiphertextVector64,
+        ksk: &CudaLweKeyswitchKey64,
+        k: usize,
+    ) {
+        execute_lwe_ciphertext_vector_k_keyswitch_on_gpu::<u64>(
+            self.get_cuda_streams(),
+            &mut output.0,
+            &input.0,
+            &ksk.0,
+            k,
+            self.get_number_of_gpus(),
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_pointer.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_pointer.rs
new file mode 100644
index 00000000..d740823d
--- /dev/null
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/lwe_ciphertext_vector_pointer.rs
@@ -0,0 +1,43 @@
+// This file was newly added by the authors of cuparmesan
+use crate::backends::cuda::implementation::engines::{CudaEngine, CudaError};
+use crate::backends::cuda::implementation::entities::{
+    CudaLweCiphertextVector64,
+};
+use crate::backends::cuda::private::crypto::lwe::list::{
+    copy_lwe_ciphertext_vector_from_cpu_to_gpu, copy_lwe_ciphertext_vector_from_gpu_to_cpu,
+    CudaLweList,
+};
+use crate::backends::cuda::private::device::GpuIndex;
+use crate::backends::cuda::private::{compute_number_of_samples_on_gpu, number_of_active_gpus};
+use crate::commons::crypto::lwe::LweList;
+use crate::prelude::{
+    CiphertextCount, LweCiphertextVector64,
+    LweCiphertextVectorMutView64, LweCiphertextVectorView64,
+};
+use crate::specification::engines::{
+    LweCiphertextVectorPointerEngine, LweCiphertextVectorPointerError,
+};
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+impl From<CudaError> for LweCiphertextVectorPointerError<CudaError> {
+    fn from(err: CudaError) -> Self {
+        Self::Engine(err)
+    }
+}
+
+impl LweCiphertextVectorPointerEngine<CudaLweCiphertextVector64, CudaLweCiphertextVector64>
+    for CudaEngine
+{
+    fn pointer_lwe_ciphertext_vector(
+        &mut self,
+        input: &CudaLweCiphertextVector64,
+    ) -> Result<CudaLweCiphertextVector64, LweCiphertextVectorPointerError<CudaError>> {
+
+        Ok(unsafe { CudaLweCiphertextVector64(CudaLweList::<u64> {
+            d_vecs: &input.0.d_vecs,
+            lwe_ciphertext_count: input.lwe_ciphertext_count(),
+            lwe_dimension: input.lwe_dimension(),
+        })
+        })
+    }
+}
diff --git a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/mod.rs b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/mod.rs
index 20bacd99..5caadbdd 100644
--- a/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/mod.rs
+++ b/concrete-core/src/backends/cuda/implementation/engines/cuda_engine/mod.rs
@@ -78,8 +78,23 @@ mod lwe_ciphertext_conversion;
 mod lwe_ciphertext_discarding_bootstrap;
 mod lwe_ciphertext_discarding_conversion;
 mod lwe_ciphertext_discarding_keyswitch;
+mod lwe_ciphertext_discarding_addition; // This function was newly added by the authors of cuparmesan
 mod lwe_ciphertext_vector_conversion;
+mod lwe_ciphertext_vector_discarding_addition;
+mod lwe_ciphertext_vector_discarding_and; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_addition_local; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_shiftaddition; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_multbyconst; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_copy_at; // This function was newly added by the authors of cuparmesan
 mod lwe_ciphertext_vector_discarding_bootstrap;
 mod lwe_ciphertext_vector_discarding_conversion;
 mod lwe_ciphertext_vector_discarding_keyswitch;
+mod lwe_ciphertext_vector_discarding_max; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_opposite;
+mod lwe_ciphertext_vector_discarding_rotation; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_rotation_all; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_opposite_inplace; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_fusing_addition; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_k_discarding_addition; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_k_discarding_keyswitch; // This function was newly added by the authors of cuparmesan
 mod lwe_keyswitch_key_conversion;
diff --git a/concrete-core/src/backends/cuda/private/crypto/bootstrap/mod.rs b/concrete-core/src/backends/cuda/private/crypto/bootstrap/mod.rs
index 455e517b..671c7291 100644
--- a/concrete-core/src/backends/cuda/private/crypto/bootstrap/mod.rs
+++ b/concrete-core/src/backends/cuda/private/crypto/bootstrap/mod.rs
@@ -174,3 +174,58 @@ pub(crate) unsafe fn execute_lwe_ciphertext_vector_amortized_bootstrap_on_gpu<
         );
     }
 }
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_k_amortized_bootstrap_on_gpu<
+    T: UnsignedInteger,
+>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input: &CudaLweList<T>,
+    acc: &CudaGlweList<T>,
+    bsk: &CudaBootstrapKey<T>,
+    k: usize,
+    number_of_available_gpus: NumberOfGpus,
+    cuda_shared_memory: SharedMemoryAmount,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(k),
+    );
+    let samples_on_gpu_0 = compute_number_of_samples_on_gpu(
+        number_of_gpus,
+        CiphertextCount(k),
+        GpuIndex(0),
+    );
+
+    for (gpu_index, stream) in streams.iter().enumerate().take(number_of_gpus.0) {
+        let samples = compute_number_of_samples_on_gpu(
+            number_of_gpus,
+            CiphertextCount(k),
+            GpuIndex(gpu_index),
+        );
+        // FIXME this is hard set at the moment because concrete-core does not support a more
+        //   general API for the bootstrap
+        let test_vector_indexes = (0..samples.0 as u32).collect::<Vec<u32>>();
+        let mut d_test_vector_indexes = stream.malloc::<u32>(samples.0 as u32);
+        stream.copy_to_gpu(&mut d_test_vector_indexes, &test_vector_indexes);
+
+        stream.initialize_twiddles(bsk.polynomial_size);
+        stream.discard_bootstrap_amortized_lwe_ciphertext_vector_k::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            acc.d_vecs.get(gpu_index).unwrap(),
+            &d_test_vector_indexes,
+            input.d_vecs.get(gpu_index).unwrap(),
+            bsk.d_vecs.get(gpu_index).unwrap(),
+            k,
+            input.lwe_dimension,
+            bsk.glwe_dimension,
+            bsk.polynomial_size,
+            bsk.decomp_base_log,
+            bsk.decomp_level,
+            samples,
+            LweCiphertextIndex(samples_on_gpu_0.0 * gpu_index),
+            cuda_shared_memory,
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/private/crypto/keyswitch/mod.rs b/concrete-core/src/backends/cuda/private/crypto/keyswitch/mod.rs
index 3f63551f..c009f991 100644
--- a/concrete-core/src/backends/cuda/private/crypto/keyswitch/mod.rs
+++ b/concrete-core/src/backends/cuda/private/crypto/keyswitch/mod.rs
@@ -57,3 +57,39 @@ pub(crate) unsafe fn execute_lwe_ciphertext_vector_keyswitch_on_gpu<T: UnsignedI
         );
     }
 }
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_k_keyswitch_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input: &CudaLweList<T>,
+    ksk: &CudaLweKeyswitchKey<T>,
+    k: usize,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(k),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(k),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_keyswitch_lwe_ciphertext_vector_k::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input.d_vecs.get(gpu_index).unwrap(),
+            input.lwe_dimension,
+            output.lwe_dimension,
+            ksk.d_vecs.get(gpu_index).unwrap(),
+            k,
+            ksk.decomp_base_log,
+            ksk.decomp_level,
+            samples_per_gpu,
+        );
+    }
+}
diff --git a/concrete-core/src/backends/cuda/private/crypto/lwe/list.rs b/concrete-core/src/backends/cuda/private/crypto/lwe/list.rs
index adcf1b3b..e8d3271b 100644
--- a/concrete-core/src/backends/cuda/private/crypto/lwe/list.rs
+++ b/concrete-core/src/backends/cuda/private/crypto/lwe/list.rs
@@ -125,3 +125,748 @@ pub(crate) unsafe fn discard_copy_lwe_ciphertext_vector_from_gpu_to_cpu<T: Unsig
         last_stream.copy_to_cpu::<T>(last_chunk, input.d_vecs.last().unwrap());
     }
 }
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_opposite_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input: &CudaLweList<T>,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_opp_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input.d_vecs.get(gpu_index).unwrap(),
+            input.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_opposite_on_gpu_inplace<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(output.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(output.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_opp_lwe_ciphertext_vector_inplace::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            output.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_k_opposite_on_gpu_inplace<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    k: usize,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(k),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(k),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_opp_lwe_ciphertext_vector_inplace::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            output.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_rotation_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input: &CudaLweList<T>,
+    k: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_rotate_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input.d_vecs.get(gpu_index).unwrap(),
+            k,
+            input.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_rotation_all_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input: &CudaLweList<T>,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_rotate_all_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input.d_vecs.get(gpu_index).unwrap(),
+            input.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_and_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    input_2: &CudaLweList<T>,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input_1.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input_1.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_and_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            input_2.d_vecs.get(gpu_index).unwrap(),
+            input_1.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_extend_xy_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    input_2: &CudaLweList<T>,
+    input_3: &CudaLweList<T>,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input_1.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input_1.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_extend_xy_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            input_2.d_vecs.get(gpu_index).unwrap(),
+            input_3.d_vecs.get(gpu_index).unwrap(),
+            input_1.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_merge_xy_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input: &CudaLweList<T>,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(output.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(output.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_merge_xy_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input.d_vecs.get(gpu_index).unwrap(),
+            output.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_addition_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    input_2: &CudaLweList<T>,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input_1.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input_1.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_add_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            input_2.d_vecs.get(gpu_index).unwrap(),
+            input_1.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_addition_inplace_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input: &CudaLweList<T>,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_add_inplace_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input.d_vecs.get(gpu_index).unwrap(),
+            input.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_k_addition_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    input_2: &CudaLweList<T>,
+    k: usize,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(k),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(k),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_add_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            input_2.d_vecs.get(gpu_index).unwrap(),
+            input_1.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_add_to_local_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    i: u32,
+    d: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input_1.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input_1.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_add_to_local_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            i,
+            d,
+            input_1.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_x_plus_2y_to_local_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    i: u32,
+    d: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input_1.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input_1.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_x_plus_2y_to_local_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            i,
+            d,
+            input_1.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_sftadd_from_local_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    input_2: &CudaLweList<T>,
+    i: u32,
+    d: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(output.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(output.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_sftadd_from_local_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            input_2.d_vecs.get(gpu_index).unwrap(),
+            i,
+            d,
+            output.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_copy_from_local_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    i: u32,
+    d: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(output.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(output.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_copy_from_local_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            i,
+            d,
+            output.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_copy_from_local_for_sign_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    i: u32,
+    d: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(output.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(output.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_copy_from_local_for_sign_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            i,
+            d,
+            output.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_shiftaddition_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    input_2: &CudaLweList<T>,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input_1.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input_1.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_sftadd_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            input_2.d_vecs.get(gpu_index).unwrap(),
+            input_1.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_shiftaddition_k_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    input_2: &CudaLweList<T>,
+    k: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(k as usize),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(k as usize),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_sftadd_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            input_2.d_vecs.get(gpu_index).unwrap(),
+            input_1.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_shiftaddition_k_on_gpu_inplace<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    k: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(k as usize),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(k as usize),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.inplace_sftadd_lwe_ciphertext_vector_k::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            input_1.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_mult_by_const_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    k: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input_1.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input_1.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_mult_by_const_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            k,
+            input_1.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_k_mult_by_const_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    k: u32,
+    k2: usize,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(k2),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(k2),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_mult_by_const_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            k,
+            input_1.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_copy_at_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    k: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input_1.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input_1.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_copy_at_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            k,
+            output.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_copy_n_at_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    k: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input_1.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input_1.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_copy_n_at_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            k,
+            output.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
+
+// This function was newly added by the authors of cuparmesan
+pub(crate) unsafe fn execute_lwe_ciphertext_vector_set_at_on_gpu<T: UnsignedInteger>(
+    streams: &[CudaStream],
+    output: &mut CudaLweList<T>,
+    input_1: &CudaLweList<T>,
+    k: u32,
+    number_of_available_gpus: NumberOfGpus,
+) {
+    let number_of_gpus = number_of_active_gpus(
+        number_of_available_gpus,
+        CiphertextCount(input_1.lwe_ciphertext_count.0),
+    );
+
+    for gpu_index in 0..number_of_gpus.0 {
+        let samples_per_gpu = compute_number_of_samples_on_gpu(
+            number_of_available_gpus,
+            CiphertextCount(input_1.lwe_ciphertext_count.0),
+            GpuIndex(gpu_index),
+        );
+        let stream = &streams.get(gpu_index).unwrap();
+
+        stream.discard_set_at_lwe_ciphertext_vector::<T>(
+            output.d_vecs.get_mut(gpu_index).unwrap(),
+            input_1.d_vecs.get(gpu_index).unwrap(),
+            k,
+            output.lwe_dimension,
+            samples_per_gpu,
+        );
+    }
+}
\ No newline at end of file
diff --git a/concrete-core/src/backends/cuda/private/device.rs b/concrete-core/src/backends/cuda/private/device.rs
index 27b65083..5a8dc111 100644
--- a/concrete-core/src/backends/cuda/private/device.rs
+++ b/concrete-core/src/backends/cuda/private/device.rs
@@ -259,6 +259,47 @@ impl CudaStream {
         }
     }
 
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding bootstrap on a vector of LWE ciphertexts
+    #[allow(dead_code, clippy::too_many_arguments)]
+    pub unsafe fn discard_bootstrap_amortized_lwe_ciphertext_vector_k<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        test_vector: &CudaVec<T>,
+        test_vector_indexes: &CudaVec<u32>,
+        lwe_array_in: &CudaVec<T>,
+        bootstrapping_key: &CudaVec<f64>,
+        _k: usize,
+        lwe_dimension: LweDimension,
+        glwe_dimension: GlweDimension,
+        polynomial_size: PolynomialSize,
+        base_log: DecompositionBaseLog,
+        level: DecompositionLevelCount,
+        num_samples: NumberOfSamples,
+        lwe_idx: LweCiphertextIndex,
+        max_shared_memory: SharedMemoryAmount,
+    ) {
+        if T::BITS == 64 {
+            cuda_bootstrap_amortized_lwe_ciphertext_vector_64(
+                self.stream.0,
+                lwe_array_out.as_mut_c_ptr(),
+                test_vector.as_c_ptr(),
+                test_vector_indexes.as_c_ptr(),
+                lwe_array_in.as_c_ptr(),
+                bootstrapping_key.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                glwe_dimension.0 as u32,
+                polynomial_size.0 as u32,
+                base_log.0 as u32,
+                level.0 as u32,
+                num_samples.0 as u32,
+                num_samples.0 as u32,
+                lwe_idx.0 as u32,
+                max_shared_memory.0 as u32,
+            )
+        }
+    }
+
     /// Discarding bootstrap on a vector of LWE ciphertexts
     #[allow(dead_code, clippy::too_many_arguments)]
     pub unsafe fn discard_bootstrap_low_latency_lwe_ciphertext_vector<T: UnsignedInteger>(
@@ -355,6 +396,598 @@ impl CudaStream {
             )
         }
     }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding keyswitch on a vector of LWE ciphertexts
+    #[allow(dead_code, clippy::too_many_arguments)]
+    pub unsafe fn discard_keyswitch_lwe_ciphertext_vector_k<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in: &CudaVec<T>,
+        input_lwe_dimension: LweDimension,
+        output_lwe_dimension: LweDimension,
+        keyswitch_key: &CudaVec<T>,
+        _k: usize,
+        base_log: DecompositionBaseLog,
+        l_gadget: DecompositionLevelCount,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_keyswitch_lwe_ciphertext_vector_64(
+                self.stream.0,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in.as_c_ptr(),
+                keyswitch_key.as_c_ptr(),
+                input_lwe_dimension.0 as u32,
+                output_lwe_dimension.0 as u32,
+                base_log.0 as u32,
+                l_gadget.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding opposite on a vector of LWE ciphertexts
+    pub unsafe fn discard_opp_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in: &CudaVec<T>,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 32 {
+            cuda_negate_lwe_ciphertext_vector_32(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        } else if T::BITS == 64 {
+            cuda_negate_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding opposite on a vector of LWE ciphertexts
+    pub unsafe fn discard_opp_lwe_ciphertext_vector_inplace<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 32 {
+            cuda_negate_lwe_ciphertext_vector_32_inplace(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        } else if T::BITS == 64 {
+            cuda_negate_lwe_ciphertext_vector_64_inplace(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding opposite on a vector of LWE ciphertexts
+    pub unsafe fn discard_opp_lwe_ciphertext_vector_k_inplace<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        _k: usize,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_negate_lwe_ciphertext_vector_64_inplace(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding rotation
+    pub unsafe fn discard_rotate_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in: &CudaVec<T>,
+        k: u32,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_rotate_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in.as_c_ptr(),
+                k,
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding rotation all
+    pub unsafe fn discard_rotate_all_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in: &CudaVec<T>,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_rotate_all_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding addition of a vector of LWE ciphertexts
+    pub unsafe fn discard_add_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        lwe_array_in_2: &CudaVec<T>,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 32 {
+            cuda_add_lwe_ciphertext_vector_32(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                lwe_array_in_2.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        } else if T::BITS == 64 {
+            cuda_add_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                lwe_array_in_2.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Inplace addition of a vector of LWE ciphertexts
+    pub unsafe fn discard_add_inplace_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in: &CudaVec<T>,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        cuda_add_inplace_lwe_ciphertext_vector_64(
+            self.stream.0,
+            self.gpu_index.0 as u32,
+            lwe_array_out.as_mut_c_ptr(),
+            lwe_array_in.as_c_ptr(),
+            lwe_dimension.0 as u32,
+            num_samples.0 as u32,
+        )
+
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    // Discarding addition of a vector of LWE ciphertexts
+    pub unsafe fn discard_add_lwe_ciphertext<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        lwe_array_in_2: &CudaVec<T>,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 32 {
+            cuda_add_lwe_ciphertext_vector_32(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                lwe_array_in_2.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        } else if T::BITS == 64 {
+            cuda_add_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                lwe_array_in_2.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding addition of a vector of LWE ciphertexts
+    pub unsafe fn discard_add_to_local_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        i: u32,
+        d: u32,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_add_to_local_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                i,
+                d,
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding x+2y of a vector of LWE ciphertexts
+    pub unsafe fn discard_x_plus_2y_to_local_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        i: u32,
+        d: u32,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_x_plus_2y_to_local_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                i,
+                d,
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding shift addition of a vector of LWE ciphertexts
+    pub unsafe fn discard_sftadd_from_local_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        lwe_array_in_2: &CudaVec<T>,
+        i: u32,
+        d: u32,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_sftadd_from_local_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                lwe_array_in_2.as_c_ptr(),
+                i,
+                d,
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    pub unsafe fn discard_copy_from_local_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        i: u32,
+        d: u32,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_copy_from_local_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                i,
+                d,
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    pub unsafe fn discard_copy_from_local_for_sign_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        i: u32,
+        d: u32,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_copy_from_local_for_sign_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                i,
+                d,
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding and of a vector of LWE ciphertexts
+    pub unsafe fn discard_and_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        lwe_array_in_2: &CudaVec<T>,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_and_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                lwe_array_in_2.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding function 1 for max
+    pub unsafe fn discard_extend_xy_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        lwe_array_in_2: &CudaVec<T>,
+        lwe_array_in_3: &CudaVec<T>,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_extend_xy_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                lwe_array_in_2.as_c_ptr(),
+                lwe_array_in_3.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding function 2 for max
+    pub unsafe fn discard_merge_xy_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in: &CudaVec<T>,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_merge_xy_lwe_ciphertext_vector_64(
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding shift add of a vector of LWE ciphertexts
+    pub unsafe fn discard_sftadd_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        lwe_array_in_2: &CudaVec<T>,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_sftadd_lwe_ciphertext_vector_64( // @ concrete-cuda / cuda_bind.rs, linear_algebra.h, shiftadd.cu
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                lwe_array_in_2.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding shift add of a vector of LWE ciphertexts
+    pub unsafe fn discard_sftadd_lwe_ciphertext_vector_k<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        lwe_array_in_2: &CudaVec<T>,
+        _k: u32,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_sftadd_lwe_ciphertext_vector_64( // @ concrete-cuda / cuda_bind.rs, linear_algebra.h, shiftadd.cu
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                lwe_array_in_2.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding shift add of a vector of LWE ciphertexts
+    pub unsafe fn inplace_sftadd_lwe_ciphertext_vector_k<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_sftadd_lwe_ciphertext_vector_64_inplace( // @ concrete-cuda / cuda_bind.rs, linear_algebra.h, shiftadd.cu
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                lwe_dimension.0 as u32,
+                num_samples.0 as u32,
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding multiplication by const for a vector of LWE ciphertexts
+    pub unsafe fn discard_mult_by_const_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        k: u32,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_mult_by_const_lwe_ciphertext_vector_64( // @ concrete-cuda/src/cuda_bind.rs, concrete-cuda/cuda/include/linear_algebra.h, concrete-cuda/cuda/src/addition.cu
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                k as u32,
+                lwe_dimension.0 as u32, // To u32
+                num_samples.0 as u32, // To u32
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding copy at index i
+    pub unsafe fn discard_copy_at_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        k: u32,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_copy_at_lwe_ciphertext_vector_64( // @ concrete-cuda/src/cuda_bind.rs, concrete-cuda/cuda/include/linear_algebra.h, concrete-cuda/cuda/src/addition.cu
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                k as u32,
+                lwe_dimension.0 as u32, // To u32
+                num_samples.0 as u32, // To u32
+            )
+        }
+    }
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding copy at index i
+    pub unsafe fn discard_copy_n_at_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        k: u32,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_copy_n_at_lwe_ciphertext_vector_64( // @ concrete-cuda/src/cuda_bind.rs, concrete-cuda/cuda/include/linear_algebra.h, concrete-cuda/cuda/src/addition.cu
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                k as u32,
+                lwe_dimension.0 as u32, // To u32
+                num_samples.0 as u32, // To u32
+            )
+        }
+    }
+
+
+    // This function was newly added by the authors of cuparmesan
+    /// Discarding set at index i
+    pub unsafe fn discard_set_at_lwe_ciphertext_vector<T: UnsignedInteger>(
+        &self,
+        lwe_array_out: &mut CudaVec<T>,
+        lwe_array_in_1: &CudaVec<T>,
+        k: u32,
+        lwe_dimension: LweDimension,
+        num_samples: NumberOfSamples,
+    ) {
+        if T::BITS == 64 {
+            cuda_set_at_lwe_ciphertext_vector_64( // @ concrete-cuda/src/cuda_bind.rs, concrete-cuda/cuda/include/linear_algebra.h, concrete-cuda/cuda/src/addition.cu
+                self.stream.0,
+                self.gpu_index.0 as u32,
+                lwe_array_out.as_mut_c_ptr(),
+                lwe_array_in_1.as_c_ptr(),
+                k as u32,
+                lwe_dimension.0 as u32, // To u32
+                num_samples.0 as u32, // To u32
+            )
+        }
+    }
 }
 
 impl Drop for CudaStream {
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_addition_local.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_addition_local.rs
new file mode 100644
index 00000000..0e662a4a
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_addition_local.rs
@@ -0,0 +1,124 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+engine_error! {
+    LweCiphertextVectorDiscardingAdditionLocalError for LweCiphertextVectorDiscardingAdditionLocalEngine @
+    LweDimensionMismatch => "The input and output LWE dimensions must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertext count must be the same."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorDiscardingAdditionLocalError<EngineError> {
+    pub fn perform_generic_checks<OutputCiphertextVector, InputCiphertextVector>(
+        output: &OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+    ) -> Result<(), Self>
+    where
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if output.lwe_dimension() != input_1.lwe_dimension()
+            || output.lwe_dimension() != input_2.lwe_dimension()
+        {
+            return Err(Self::LweDimensionMismatch);
+        }
+        if output.lwe_ciphertext_count() != input_1.lwe_ciphertext_count()
+            || output.lwe_ciphertext_count() != input_2.lwe_ciphertext_count()
+        {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorDiscardingAdditionLocalEngine<InputCiphertextVector, OutputCiphertextVector>:
+    AbstractEngine
+where
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_x_plus_2y_to_local_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        i: u32,
+        d: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionLocalError<Self::EngineError>>;
+
+    unsafe fn discard_x_plus_2y_to_local_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        i: u32,
+        d: u32,
+    );
+
+    fn discard_add_to_local_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        i: u32,
+        d: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionLocalError<Self::EngineError>>;
+
+    unsafe fn discard_add_to_local_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        i: u32,
+        d: u32,
+    );
+
+    fn discard_sftadd_from_local_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+        i: u32,
+        d: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionLocalError<Self::EngineError>>;
+
+    unsafe fn discard_sftadd_from_local_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+        i: u32,
+        d: u32,
+    );
+
+    fn discard_copy_from_local_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        i: u32,
+        d: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionLocalError<Self::EngineError>>;
+
+    unsafe fn discard_copy_from_local_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        i: u32,
+        d: u32,
+    );
+
+    fn discard_copy_from_local_for_sign_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        i: u32,
+        d: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingAdditionLocalError<Self::EngineError>>;
+
+    unsafe fn discard_copy_from_local_for_sign_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        i: u32,
+        d: u32,
+    );
+
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_and.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_and.rs
new file mode 100644
index 00000000..d410f8b9
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_and.rs
@@ -0,0 +1,56 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+engine_error! {
+    LweCiphertextVectorDiscardingAndError for LweCiphertextVectorDiscardingAndEngine @
+    LweDimensionMismatch => "The input and output LWE dimensions must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertext count must be the same."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorDiscardingAndError<EngineError> {
+    pub fn perform_generic_checks<OutputCiphertextVector, InputCiphertextVector>(
+        output: &OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+    ) -> Result<(), Self>
+    where
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if output.lwe_dimension() != input_1.lwe_dimension()
+            || output.lwe_dimension() != input_2.lwe_dimension()
+        {
+            return Err(Self::LweDimensionMismatch);
+        }
+        if output.lwe_ciphertext_count() != input_1.lwe_ciphertext_count()
+            || output.lwe_ciphertext_count() != input_2.lwe_ciphertext_count()
+        {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorDiscardingAndEngine<InputCiphertextVector, OutputCiphertextVector>:
+    AbstractEngine
+where
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_and_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+    ) -> Result<(), LweCiphertextVectorDiscardingAndError<Self::EngineError>>;
+
+    unsafe fn discard_and_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+    );
+
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_copy_at.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_copy_at.rs
new file mode 100644
index 00000000..a8ed74d2
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_copy_at.rs
@@ -0,0 +1,83 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+engine_error! {
+    LweCiphertextVectorDiscardingCopyAtError for LweCiphertextVectorDiscardingCopyAtEngine @
+    LweDimensionMismatch => "The input and output LWE dimensions must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertext count must be the same."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorDiscardingCopyAtError<EngineError> {
+    pub fn perform_generic_checks<OutputCiphertextVector, InputCiphertextVector>(
+        output: &OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+    ) -> Result<(), Self>
+    where
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if output.lwe_dimension() != input_1.lwe_dimension()
+            || output.lwe_dimension() != input_2.lwe_dimension()
+        {
+            return Err(Self::LweDimensionMismatch);
+        }
+        if output.lwe_ciphertext_count() != input_1.lwe_ciphertext_count()
+            || output.lwe_ciphertext_count() != input_2.lwe_ciphertext_count()
+        {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorDiscardingCopyAtEngine<InputCiphertextVector, OutputCiphertextVector>:
+    AbstractEngine
+where
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_copy_at_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingCopyAtError<Self::EngineError>>;
+
+    unsafe fn discard_copy_at_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+    );
+
+    fn discard_copy_n_at_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingCopyAtError<Self::EngineError>>;
+
+    unsafe fn discard_copy_n_at_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+    );
+
+    fn discard_set_at_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingCopyAtError<Self::EngineError>>;
+
+    unsafe fn discard_set_at_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+    );
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_max.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_max.rs
new file mode 100644
index 00000000..4a7fcdcb
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_max.rs
@@ -0,0 +1,70 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+engine_error! {
+    LweCiphertextVectorDiscardingMaxError for LweCiphertextVectorDiscardingMaxEngine @
+    LweDimensionMismatch => "The input and output LWE dimensions must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertext count must be the same."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorDiscardingMaxError<EngineError> {
+    pub fn perform_generic_checks<OutputCiphertextVector, InputCiphertextVector>(
+        output: &OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+    ) -> Result<(), Self>
+    where
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if output.lwe_dimension() != input_1.lwe_dimension()
+            || output.lwe_dimension() != input_2.lwe_dimension()
+        {
+            return Err(Self::LweDimensionMismatch);
+        }
+        if output.lwe_ciphertext_count() != input_1.lwe_ciphertext_count()
+            || output.lwe_ciphertext_count() != input_2.lwe_ciphertext_count()
+        {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorDiscardingMaxEngine<InputCiphertextVector, OutputCiphertextVector>:
+    AbstractEngine
+where
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_extend_xy_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+        input_3: &InputCiphertextVector,
+    ) -> Result<(), LweCiphertextVectorDiscardingMaxError<Self::EngineError>>;
+
+    unsafe fn discard_extend_xy_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+        input_3: &InputCiphertextVector,
+    );
+
+    fn discard_merge_xy_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input: &InputCiphertextVector,
+    ) -> Result<(), LweCiphertextVectorDiscardingMaxError<Self::EngineError>>;
+
+    unsafe fn discard_merge_xy_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input: &InputCiphertextVector,
+    );
+
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_mult_by_const.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_mult_by_const.rs
new file mode 100644
index 00000000..b9e2dea1
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_mult_by_const.rs
@@ -0,0 +1,72 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+engine_error! {
+    LweCiphertextVectorDiscardingMultByConstError for LweCiphertextVectorDiscardingMultByConstEngine @
+    LweDimensionMismatch => "The input and output LWE dimensions must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertext count must be the same."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorDiscardingMultByConstError<EngineError> {
+    pub fn perform_generic_checks<OutputCiphertextVector, InputCiphertextVector>(
+        output: &OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+    ) -> Result<(), Self>
+    where
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if output.lwe_dimension() != input_1.lwe_dimension()
+            || output.lwe_dimension() != input_2.lwe_dimension()
+        {
+            return Err(Self::LweDimensionMismatch);
+        }
+        if output.lwe_ciphertext_count() != input_1.lwe_ciphertext_count()
+            || output.lwe_ciphertext_count() != input_2.lwe_ciphertext_count()
+        {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorDiscardingMultByConstEngine<InputCiphertextVector, OutputCiphertextVector>:
+    AbstractEngine
+where
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_mult_by_const_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingMultByConstError<Self::EngineError>>;
+
+    unsafe fn discard_mult_by_const_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+    );
+
+    fn discard_mult_by_const_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+        k2: usize,
+    ) -> Result<(), LweCiphertextVectorDiscardingMultByConstError<Self::EngineError>>;
+
+    unsafe fn discard_mult_by_const_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+        k2: usize,
+    );
+
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_opposite_inplace.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_opposite_inplace.rs
new file mode 100644
index 00000000..14e94680
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_opposite_inplace.rs
@@ -0,0 +1,60 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+engine_error! {
+    LweCiphertextVectorDiscardingOppositeInplaceError for LweCiphertextVectorDiscardingOppositeInplaceEngine @
+    LweDimensionMismatch => "The input and output LWE dimension must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertext count must be the same."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorDiscardingOppositeInplaceError<EngineError> {
+    pub fn perform_generic_checks<InputCiphertextVector, OutputCiphertextVector>(
+        output: &OutputCiphertextVector,
+        input: &InputCiphertextVector,
+    ) -> Result<(), Self>
+    where
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if input.lwe_dimension() != output.lwe_dimension() {
+            return Err(Self::LweDimensionMismatch);
+        }
+
+        if input.lwe_ciphertext_count() != output.lwe_ciphertext_count() {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorDiscardingOppositeInplaceEngine<InputCiphertextVector, OutputCiphertextVector>:
+    AbstractEngine
+where
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_opp_lwe_ciphertext_vector_inplace(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+    ) -> Result<(), LweCiphertextVectorDiscardingOppositeInplaceError<Self::EngineError>>;
+
+    unsafe fn discard_opp_lwe_ciphertext_vector_inplace_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+    );
+
+    fn discard_opp_lwe_ciphertext_vector_k_inplace(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        k: usize,
+    ) -> Result<(), LweCiphertextVectorDiscardingOppositeInplaceError<Self::EngineError>>;
+
+    unsafe fn discard_opp_lwe_ciphertext_vector_k_inplace_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        k: usize,
+    );
+
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_rotation.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_rotation.rs
new file mode 100644
index 00000000..c99357a3
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_rotation.rs
@@ -0,0 +1,51 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+engine_error! {
+    LweCiphertextVectorDiscardingRotationError for LweCiphertextVectorDiscardingRotationEngine @
+    LweDimensionMismatch => "The input and output LWE dimension must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertext count must be the same."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorDiscardingRotationError<EngineError> {
+    pub fn perform_generic_checks<InputCiphertextVector, OutputCiphertextVector>(
+        output: &OutputCiphertextVector,
+        input: &InputCiphertextVector,
+    ) -> Result<(), Self>
+    where
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if input.lwe_dimension() != output.lwe_dimension() {
+            return Err(Self::LweDimensionMismatch);
+        }
+
+        if input.lwe_ciphertext_count() != output.lwe_ciphertext_count() {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorDiscardingRotationEngine<InputCiphertextVector, OutputCiphertextVector>:
+    AbstractEngine
+where
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_rotate_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input: &InputCiphertextVector,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingRotationError<Self::EngineError>>;
+
+    unsafe fn discard_rotate_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input: &InputCiphertextVector,
+        k: u32,
+    );
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_rotation_all.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_rotation_all.rs
new file mode 100644
index 00000000..0d745c2a
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_rotation_all.rs
@@ -0,0 +1,49 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+engine_error! {
+    LweCiphertextVectorDiscardingRotationAllError for LweCiphertextVectorDiscardingRotationAllEngine @
+    LweDimensionMismatch => "The input and output LWE dimension must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertext count must be the same."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorDiscardingRotationAllError<EngineError> {
+    pub fn perform_generic_checks<InputCiphertextVector, OutputCiphertextVector>(
+        output: &OutputCiphertextVector,
+        input: &InputCiphertextVector,
+    ) -> Result<(), Self>
+    where
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if input.lwe_dimension() != output.lwe_dimension() {
+            return Err(Self::LweDimensionMismatch);
+        }
+
+        if input.lwe_ciphertext_count() != output.lwe_ciphertext_count() {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorDiscardingRotationAllEngine<InputCiphertextVector, OutputCiphertextVector>:
+    AbstractEngine
+where
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_rotate_all_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input: &InputCiphertextVector,
+    ) -> Result<(), LweCiphertextVectorDiscardingRotationAllError<Self::EngineError>>;
+
+    unsafe fn discard_rotate_all_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input: &InputCiphertextVector,
+    );
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_shiftaddition.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_shiftaddition.rs
new file mode 100644
index 00000000..0853d503
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_discarding_shiftaddition.rs
@@ -0,0 +1,85 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+engine_error! {
+    LweCiphertextVectorDiscardingShiftAdditionError for LweCiphertextVectorDiscardingShiftAdditionEngine @
+    LweDimensionMismatch => "The input and output LWE dimensions must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertext count must be the same."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorDiscardingShiftAdditionError<EngineError> {
+    pub fn perform_generic_checks<OutputCiphertextVector, InputCiphertextVector>(
+        output: &OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+    ) -> Result<(), Self>
+    where
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if output.lwe_dimension() != input_1.lwe_dimension()
+            || output.lwe_dimension() != input_2.lwe_dimension()
+        {
+            return Err(Self::LweDimensionMismatch);
+        }
+        if output.lwe_ciphertext_count() != input_1.lwe_ciphertext_count()
+            || output.lwe_ciphertext_count() != input_2.lwe_ciphertext_count()
+        {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorDiscardingShiftAdditionEngine<InputCiphertextVector, OutputCiphertextVector>:
+    AbstractEngine
+where
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_sftadd_lwe_ciphertext_vector(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+    ) -> Result<(), LweCiphertextVectorDiscardingShiftAdditionError<Self::EngineError>>;
+
+    unsafe fn discard_sftadd_lwe_ciphertext_vector_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+    );
+
+    fn discard_sftadd_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingShiftAdditionError<Self::EngineError>>;
+
+    unsafe fn discard_sftadd_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+        k: u32,
+    );
+
+    fn inplace_sftadd_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+    ) -> Result<(), LweCiphertextVectorDiscardingShiftAdditionError<Self::EngineError>>;
+
+    unsafe fn inplace_sftadd_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        k: u32,
+    );
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_k_discarding_addition.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_k_discarding_addition.rs
new file mode 100644
index 00000000..6bb399d6
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_k_discarding_addition.rs
@@ -0,0 +1,58 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+engine_error! {
+    LweCiphertextVectorKDiscardingAdditionError for LweCiphertextVectorKDiscardingAdditionEngine @
+    LweDimensionMismatch => "The input and output LWE dimensions must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertext count must be the same."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorKDiscardingAdditionError<EngineError> {
+    pub fn perform_generic_checks<OutputCiphertextVector, InputCiphertextVector>(
+        output: &OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+    ) -> Result<(), Self>
+    where
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if output.lwe_dimension() != input_1.lwe_dimension()
+            || output.lwe_dimension() != input_2.lwe_dimension()
+        {
+            return Err(Self::LweDimensionMismatch);
+        }
+        if output.lwe_ciphertext_count() != input_1.lwe_ciphertext_count()
+            || output.lwe_ciphertext_count() != input_2.lwe_ciphertext_count()
+        {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorKDiscardingAdditionEngine<InputCiphertextVector, OutputCiphertextVector>:
+    AbstractEngine
+where
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_add_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+        k: usize,
+    ) -> Result<(), LweCiphertextVectorKDiscardingAdditionError<Self::EngineError>>;
+
+    unsafe fn discard_add_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input_1: &InputCiphertextVector,
+        input_2: &InputCiphertextVector,
+        k: usize,
+    );
+
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_k_discarding_bootstrap.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_k_discarding_bootstrap.rs
new file mode 100644
index 00000000..4d00a735
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_k_discarding_bootstrap.rs
@@ -0,0 +1,91 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+
+use crate::specification::entities::{
+    GlweCiphertextVectorEntity, LweBootstrapKeyEntity, LweCiphertextVectorEntity,
+};
+
+engine_error! {
+    LweCiphertextVectorKDiscardingBootstrapError for LweCiphertextVectorKDiscardingBootstrapEngine @
+    InputLweDimensionMismatch => "The input vector and key input LWE dimension must be the same.",
+    OutputLweDimensionMismatch => "The output vector and key output LWE dimension must be the same.",
+    AccumulatorGlweDimensionMismatch => "The accumulator vector and key GLWE dimension must be the same.",
+    AccumulatorPolynomialSizeMismatch => "The accumulator vector and key polynomial size must be the same.",
+    AccumulatorCountMismatch => "The accumulator count and input ciphertext count must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertext count must be the same."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorKDiscardingBootstrapError<EngineError> {
+    pub fn perform_generic_checks<
+        BootstrapKey,
+        AccumulatorVector,
+        InputCiphertextVector,
+        OutputCiphertextVector,
+    >(
+        output: &OutputCiphertextVector,
+        input: &InputCiphertextVector,
+        acc: &AccumulatorVector,
+        bsk: &BootstrapKey,
+    ) -> Result<(), Self>
+    where
+        BootstrapKey: LweBootstrapKeyEntity,
+        AccumulatorVector: GlweCiphertextVectorEntity,
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if bsk.input_lwe_dimension() != input.lwe_dimension() {
+            return Err(Self::InputLweDimensionMismatch);
+        }
+
+        if bsk.output_lwe_dimension() != output.lwe_dimension() {
+            return Err(Self::OutputLweDimensionMismatch);
+        }
+
+        if bsk.glwe_dimension() != acc.glwe_dimension() {
+            return Err(Self::AccumulatorGlweDimensionMismatch);
+        }
+
+        if bsk.polynomial_size() != acc.polynomial_size() {
+            return Err(Self::AccumulatorPolynomialSizeMismatch);
+        }
+        if acc.glwe_ciphertext_count().0 != input.lwe_ciphertext_count().0 {
+            return Err(Self::AccumulatorCountMismatch);
+        }
+
+        if input.lwe_ciphertext_count() != output.lwe_ciphertext_count() {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorKDiscardingBootstrapEngine<
+    BootstrapKey,
+    AccumulatorVector,
+    InputCiphertextVector,
+    OutputCiphertextVector,
+>: AbstractEngine where
+    BootstrapKey: LweBootstrapKeyEntity,
+    AccumulatorVector: GlweCiphertextVectorEntity,
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_bootstrap_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input: &InputCiphertextVector,
+        acc: &AccumulatorVector,
+        bsk: &BootstrapKey,
+        k: usize,
+    ) -> Result<(), LweCiphertextVectorKDiscardingBootstrapError<Self::EngineError>>;
+
+    unsafe fn discard_bootstrap_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input: &InputCiphertextVector,
+        acc: &AccumulatorVector,
+        bsk: &BootstrapKey,
+        k: usize,
+    );
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_k_discarding_keyswitch.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_k_discarding_keyswitch.rs
new file mode 100644
index 00000000..107f1405
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_k_discarding_keyswitch.rs
@@ -0,0 +1,66 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+
+use crate::specification::entities::{LweCiphertextVectorEntity, LweKeyswitchKeyEntity};
+
+engine_error! {
+    LweCiphertextVectorKDiscardingKeyswitchError for LweCiphertextVectorKDiscardingKeyswitchEngine @
+    InputLweDimensionMismatch => "The input ciphertext vector and keyswitch key input LWE \
+                                  dimension must be the same.",
+    OutputLweDimensionMismatch => "The output ciphertext vector and keyswitch key output LWE \
+                                   dimension must be the same.",
+    CiphertextCountMismatch => "The input and output ciphertexts have different ciphertext counts."
+}
+
+impl<EngineError: std::error::Error> LweCiphertextVectorKDiscardingKeyswitchError<EngineError> {
+    pub fn perform_generic_checks<KeyswitchKey, InputCiphertextVector, OutputCiphertextVector>(
+        output: &mut OutputCiphertextVector,
+        input: &InputCiphertextVector,
+        ksk: &KeyswitchKey,
+    ) -> Result<(), Self>
+    where
+        KeyswitchKey: LweKeyswitchKeyEntity,
+        InputCiphertextVector: LweCiphertextVectorEntity,
+        OutputCiphertextVector: LweCiphertextVectorEntity,
+    {
+        if input.lwe_dimension() != ksk.input_lwe_dimension() {
+            return Err(Self::InputLweDimensionMismatch);
+        }
+
+        if output.lwe_dimension() != ksk.output_lwe_dimension() {
+            return Err(Self::OutputLweDimensionMismatch);
+        }
+
+        if input.lwe_ciphertext_count() != output.lwe_ciphertext_count() {
+            return Err(Self::CiphertextCountMismatch);
+        }
+        Ok(())
+    }
+}
+
+pub trait LweCiphertextVectorKDiscardingKeyswitchEngine<
+    KeyswitchKey,
+    InputCiphertextVector,
+    OutputCiphertextVector,
+>: AbstractEngine where
+    KeyswitchKey: LweKeyswitchKeyEntity,
+    InputCiphertextVector: LweCiphertextVectorEntity,
+    OutputCiphertextVector: LweCiphertextVectorEntity,
+{
+    fn discard_keyswitch_lwe_ciphertext_vector_k(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input: &InputCiphertextVector,
+        ksk: &KeyswitchKey,
+        k: usize,
+    ) -> Result<(), LweCiphertextVectorKDiscardingKeyswitchError<Self::EngineError>>;
+
+    unsafe fn discard_keyswitch_lwe_ciphertext_vector_k_unchecked(
+        &mut self,
+        output: &mut OutputCiphertextVector,
+        input: &InputCiphertextVector,
+        ksk: &KeyswitchKey,
+        k: usize,
+    );
+}
diff --git a/concrete-core/src/specification/engines/lwe_ciphertext_vector_pointer.rs b/concrete-core/src/specification/engines/lwe_ciphertext_vector_pointer.rs
new file mode 100644
index 00000000..72707305
--- /dev/null
+++ b/concrete-core/src/specification/engines/lwe_ciphertext_vector_pointer.rs
@@ -0,0 +1,19 @@
+// This file was newly added by the authors of cuparmesan
+use super::engine_error;
+use crate::specification::engines::AbstractEngine;
+use crate::specification::entities::LweCiphertextVectorEntity;
+
+engine_error! {
+    LweCiphertextVectorPointerError for LweCiphertextVectorPointerEngine @
+}
+
+pub trait LweCiphertextVectorPointerEngine<Input, Output>: AbstractEngine
+where
+    Input: LweCiphertextVectorEntity,
+    Output: LweCiphertextVectorEntity,
+{
+    fn pointer_lwe_ciphertext_vector(
+        &mut self,
+        input: &Input,
+    ) -> Result<Output, LweCiphertextVectorPointerError<Self::EngineError>>;
+}
diff --git a/concrete-core/src/specification/engines/mod.rs b/concrete-core/src/specification/engines/mod.rs
index 33cac8b7..de594cc8 100644
--- a/concrete-core/src/specification/engines/mod.rs
+++ b/concrete-core/src/specification/engines/mod.rs
@@ -243,16 +243,28 @@ mod lwe_ciphertext_vector_conversion;
 mod lwe_ciphertext_vector_creation;
 mod lwe_ciphertext_vector_decryption;
 mod lwe_ciphertext_vector_discarding_addition;
+mod lwe_ciphertext_vector_k_discarding_addition; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_addition_local; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_and; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_shiftaddition; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_max; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_mult_by_const; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_copy_at; // This function was newly added by the authors of cuparmesan
 mod lwe_ciphertext_vector_discarding_affine_transformation;
 mod lwe_ciphertext_vector_discarding_bootstrap;
+mod lwe_ciphertext_vector_k_discarding_bootstrap; // This function was newly added by the authors of cuparmesan
 mod lwe_ciphertext_vector_discarding_circuit_bootstrap_boolean;
 mod lwe_ciphertext_vector_discarding_circuit_bootstrap_boolean_vertical_packing;
 mod lwe_ciphertext_vector_discarding_conversion;
 mod lwe_ciphertext_vector_discarding_decryption;
 mod lwe_ciphertext_vector_discarding_encryption;
 mod lwe_ciphertext_vector_discarding_keyswitch;
+mod lwe_ciphertext_vector_k_discarding_keyswitch; // This function was newly added by the authors of cuparmesan
 mod lwe_ciphertext_vector_discarding_loading;
 mod lwe_ciphertext_vector_discarding_opposite;
+mod lwe_ciphertext_vector_discarding_opposite_inplace; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_rotation; // This function was newly added by the authors of cuparmesan
+mod lwe_ciphertext_vector_discarding_rotation_all; // This function was newly added by the authors of cuparmesan
 mod lwe_ciphertext_vector_discarding_subtraction;
 mod lwe_ciphertext_vector_encryption;
 mod lwe_ciphertext_vector_fusing_addition;
@@ -394,16 +406,28 @@ pub use lwe_ciphertext_vector_conversion::*;
 pub use lwe_ciphertext_vector_creation::*;
 pub use lwe_ciphertext_vector_decryption::*;
 pub use lwe_ciphertext_vector_discarding_addition::*;
+pub use lwe_ciphertext_vector_k_discarding_addition::*; // This function was newly added by the authors of cuparmesan
+pub use lwe_ciphertext_vector_discarding_addition_local::*; // This function was newly added by the authors of cuparmesan
+pub use lwe_ciphertext_vector_discarding_and::*;    // This function was newly added by the authors of cuparmesan
+pub use lwe_ciphertext_vector_discarding_shiftaddition::*; // This function was newly added by the authors of cuparmesan
+pub use lwe_ciphertext_vector_discarding_max::*; // This function was newly added by the authors of cuparmesan
+pub use lwe_ciphertext_vector_discarding_mult_by_const::*; // This function was newly added by the authors of cuparmesan
+pub use lwe_ciphertext_vector_discarding_copy_at::*; // This function was newly added by the authors of cuparmesan
 pub use lwe_ciphertext_vector_discarding_affine_transformation::*;
 pub use lwe_ciphertext_vector_discarding_bootstrap::*;
+pub use lwe_ciphertext_vector_k_discarding_bootstrap::*; // This function was newly added by the authors of cuparmesan
 pub use lwe_ciphertext_vector_discarding_circuit_bootstrap_boolean::*;
 pub use lwe_ciphertext_vector_discarding_circuit_bootstrap_boolean_vertical_packing::*;
 pub use lwe_ciphertext_vector_discarding_conversion::*;
 pub use lwe_ciphertext_vector_discarding_decryption::*;
 pub use lwe_ciphertext_vector_discarding_encryption::*;
 pub use lwe_ciphertext_vector_discarding_keyswitch::*;
+pub use lwe_ciphertext_vector_k_discarding_keyswitch::*; // This function was newly added by the authors of cuparmesan
 pub use lwe_ciphertext_vector_discarding_loading::*;
 pub use lwe_ciphertext_vector_discarding_opposite::*;
+pub use lwe_ciphertext_vector_discarding_rotation::*; // This function was newly added by the authors of cuparmesan
+pub use lwe_ciphertext_vector_discarding_rotation_all::*; // This function was newly added by the authors of cuparmesan
+pub use lwe_ciphertext_vector_discarding_opposite_inplace::*; // This function was newly added by the authors of cuparmesan
 pub use lwe_ciphertext_vector_discarding_subtraction::*;
 pub use lwe_ciphertext_vector_encryption::*;
 pub use lwe_ciphertext_vector_fusing_addition::*;
diff --git a/concrete-cuda/cuda/CMakeLists.txt b/concrete-cuda/cuda/CMakeLists.txt
index 640cfd68..f9f86d85 100644
--- a/concrete-cuda/cuda/CMakeLists.txt
+++ b/concrete-cuda/cuda/CMakeLists.txt
@@ -1,3 +1,4 @@
+# This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 cmake_minimum_required(VERSION 3.8 FATAL_ERROR)
 project(concrete_cuda LANGUAGES CXX CUDA)
 
diff --git a/concrete-cuda/cuda/include/linear_algebra.h b/concrete-cuda/cuda/include/linear_algebra.h
new file mode 100644
index 00000000..9dee1778
--- /dev/null
+++ b/concrete-cuda/cuda/include/linear_algebra.h
@@ -0,0 +1,185 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
+#ifndef CUDA_LINALG_H_
+#define CUDA_LINALG_H_
+
+#include <cstdint>
+
+extern "C" {
+
+void cuda_negate_lwe_ciphertext_vector_32(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          void *lwe_array_in,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count);
+void cuda_negate_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          void *lwe_array_in,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_rotate_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          void *lwe_array_in,
+                                          uint32_t k,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_rotate_all_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          void *lwe_array_in,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_negate_lwe_ciphertext_vector_32_inplace(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_negate_lwe_ciphertext_vector_64_inplace(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count);
+
+void cuda_add_lwe_ciphertext_vector_32(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+void cuda_add_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+// This function was newly added by the authors of cuparmesan
+void cuda_add_inplace_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_x_plus_2y_to_local_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t k,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_add_to_local_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t k,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_sftadd_from_local_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       uint32_t i,
+                                       uint32_t k,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_copy_from_local_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t k,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_copy_from_local_for_sign_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t k,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_and_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_extend_xy_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       void *lwe_array_in_3,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_merge_xy_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in,
+                                       uint32_t output_lwe_dimension,
+                                       uint32_t output_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_sftadd_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_sftadd_lwe_ciphertext_vector_64_inplace(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_mult_by_const_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t k,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_copy_at_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_copy_n_at_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+
+// This function was newly added by the authors of cuparmesan
+void cuda_set_at_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count);
+}
+
+#endif // CUDA_LINALG_H_
diff --git a/concrete-cuda/cuda/src/CMakeLists.txt b/concrete-cuda/cuda/src/CMakeLists.txt
index 5260a879..f7d0d1d1 100644
--- a/concrete-cuda/cuda/src/CMakeLists.txt
+++ b/concrete-cuda/cuda/src/CMakeLists.txt
@@ -1,5 +1,6 @@
-set(SOURCES ${CMAKE_SOURCE_DIR}/${INCLUDE_DIR}/bootstrap.h 
-    ${CMAKE_SOURCE_DIR}/${INCLUDE_DIR}/keyswitch.h)
+set(SOURCES ${CMAKE_SOURCE_DIR}/${INCLUDE_DIR}/bootstrap.h
+        ${CMAKE_SOURCE_DIR}/${INCLUDE_DIR}/keyswitch.h
+        ${CMAKE_SOURCE_DIR}/${INCLUDE_DIR}/linear_algebra.h)
 file(GLOB SOURCES
      "*.cu"
      "*.h"
diff --git a/concrete-cuda/cuda/src/addition.cu b/concrete-cuda/cuda/src/addition.cu
new file mode 100644
index 00000000..d75ca6a1
--- /dev/null
+++ b/concrete-cuda/cuda/src/addition.cu
@@ -0,0 +1,124 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
+#include "addition.cuh"
+
+void cuda_add_lwe_ciphertext_vector_32(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_addition(v_stream, gpu_index, static_cast<uint32_t *>(lwe_array_out),
+                static_cast<uint32_t *>(lwe_array_in_1),
+                static_cast<uint32_t *>(lwe_array_in_2), input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+void cuda_add_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_addition(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                static_cast<uint64_t *>(lwe_array_in_2), input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+// This function was newly added by the authors of cuparmesan
+void cuda_add_inplace_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_addition_inplace(v_stream, gpu_index,
+                static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in), input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+
+// This function was newly added by the authors of cuparmesan
+void cuda_add_to_local_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t d,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_addition_to_local(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                i, d,
+                input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+// This function was newly added by the authors of cuparmesan
+void cuda_x_plus_2y_to_local_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t d,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_x_plus_2y_to_local(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                i, d,
+                input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+
+// This function was newly added by the authors of cuparmesan
+void cuda_sftadd_from_local_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       uint32_t i,
+                                       uint32_t d,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_shiftadd_from_local(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                static_cast<uint64_t *>(lwe_array_in_2),
+                i, d,
+                input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+// This function was newly added by the authors of cuparmesan
+void cuda_copy_from_local_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t d,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_copy_from_local(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                i, d,
+                input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+// This function was newly added by the authors of cuparmesan
+void cuda_copy_from_local_for_sign_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t d,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_copy_from_local_for_sign(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                i, d,
+                input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
\ No newline at end of file
diff --git a/concrete-cuda/cuda/src/addition.cuh b/concrete-cuda/cuda/src/addition.cuh
new file mode 100644
index 00000000..43642d50
--- /dev/null
+++ b/concrete-cuda/cuda/src/addition.cuh
@@ -0,0 +1,271 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
+#ifndef CUDA_ADD_H
+#define CUDA_ADD_H
+
+#ifdef __CDT_PARSER__
+#undef __CUDA_RUNTIME_H__
+#include <cuda_runtime.h>
+#include <helper_cuda.h>
+#endif
+
+#include "linear_algebra.h"
+#include "utils/kernel_dimensions.cuh"
+
+template <typename T>
+__global__ void addition(T *output, T *input_1, T *input_2,
+                         uint32_t num_entries) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x; // This line was modified by the authors of cuparmesan
+  if (index < num_entries) { // This line was modified by the authors of cuparmesan
+    // Here we take advantage of the wrapping behaviour of uint
+    output[index] = input_1[index] + input_2[index];
+  }
+}
+
+template <typename T>
+__host__ void host_addition(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input_1, T *input_2,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  // lwe_size includes the presence of the body
+  // whereas lwe_dimension is the number of elements in the mask
+  int lwe_size = input_lwe_dimension + 1;
+  // Create a 1-dimensional grid of threads
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = input_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  addition<<<grid, thds, 0, *stream>>>(output, input_1, input_2, num_entries);
+
+  cudaStreamSynchronize(*stream);
+}
+
+// This function was newly added by the authors of cuparmesan
+template <typename T>
+__global__ void addition_inplace(T *output, T *input,
+                         uint32_t num_entries) {
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    output[index] = output[index] + input[index];
+  }
+}
+
+template <typename T>
+__host__ void host_addition_inplace(void *v_stream, uint32_t gpu_index,
+                            T *output, T *input,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = input_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  addition_inplace<<<grid, thds, 0, *stream>>>(output, input, num_entries);
+  cudaStreamSynchronize(*stream);
+}
+
+// This function was newly added by the authors of cuparmesan
+template <typename T>
+__global__ void addition_to_local(T *output, T *input, uint32_t i, uint32_t d,
+                         uint32_t num_entries, uint32_t m, uint32_t n) {
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    uint32_t r = uint32_t(index%m);
+    uint32_t k = uint32_t(index/(m*(n+1)));
+    uint32_t box = uint32_t(index/m) % (n+1);
+    uint32_t left = uint32_t(pow(2, d - i + 1) * k);
+    uint32_t right = left + pow(2,d - i);
+    if(box != n){
+      output[index] = input[m*n*left + m*box + r] + input[m*n*right + m*box + r];
+    }else{
+      output[index] = output[m*(n+1)*uint32_t(pow(2,i)) - m + r];
+    }
+  }
+}
+
+// This function was newly added by the authors of cuparmesan
+template <typename T>
+__host__ void host_addition_to_local(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input, uint32_t i, uint32_t d,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int n = sqrt(input_lwe_ciphertext_count);
+  int output_lwe_ciphertext_count = pow(2, i) * (n + 1);
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = output_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  addition_to_local<<<grid, thds, 0, *stream>>>(output, input, i, d, num_entries, lwe_size, n);
+  cudaStreamSynchronize(*stream);
+}
+
+// This function was newly added by the authors of cuparmesan
+template <typename T>
+__global__ void x_plus_2y_to_local(T *output, T *input, uint32_t i, uint32_t d,
+                         uint32_t num_entries, uint32_t m, uint32_t n) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    uint32_t r = uint32_t(index%m);
+    uint32_t k = uint32_t(index/m);
+    uint32_t left = pow(2, d - i + 1) * k;
+    uint32_t right = left + pow(2,d - i);
+    output[index] = input[m*left + r] + 2 * input[m*right + r];
+  }
+}
+
+// This function was newly added by the authors of cuparmesan
+template <typename T>
+__host__ void host_x_plus_2y_to_local(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input, uint32_t i, uint32_t d,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int n = input_lwe_ciphertext_count;
+  int output_lwe_ciphertext_count = pow(2, i);
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = output_lwe_ciphertext_count * lwe_size; // n * m
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  x_plus_2y_to_local<<<grid, thds, 0, *stream>>>(output, input, i, d, num_entries, lwe_size, n);
+
+  cudaStreamSynchronize(*stream);
+}
+
+// This function was newly added by the authors of cuparmesan
+template <typename T>
+__global__ void shiftadd_from_local(T *output, T *input_1, T *input_2, uint32_t i, uint32_t d,
+                         uint32_t num_entries, uint32_t m, uint32_t n) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    uint32_t r = uint32_t(index%(m*(n+1)));
+    uint32_t k = uint32_t(index/(m*(n+1)));
+    uint32_t left = pow(2, d - i + 1) * k;
+    if(index >= m){
+      output[m*(n+1)*left + r] = input_1[index] + input_2[index - m];
+    }else{
+      output[m*(n+1)*left + r] = input_1[index] + input_2[index];
+    }
+  }
+}
+
+// This function was newly added by the authors of cuparmesan
+template <typename T>
+__host__ void host_shiftadd_from_local(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input_1, T *input_2,
+                            uint32_t i, uint32_t d,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int n = sqrt(input_lwe_ciphertext_count);
+  int output_lwe_ciphertext_count = pow(2, i) * (n+1);
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = output_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  shiftadd_from_local<<<grid, thds, 0, *stream>>>(output, input_1, input_2, i, d, num_entries, lwe_size, n);
+
+  cudaStreamSynchronize(*stream);
+}
+
+// This function was newly added by the authors of cuparmesan
+template <typename T>
+__global__ void copy_from_local(T *output, T *input, uint32_t i, uint32_t d,
+                         uint32_t num_entries, uint32_t m, uint32_t n) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    uint32_t r = uint32_t(index%m);
+    uint32_t k = uint32_t(index/(m*(n+1)));
+    uint32_t box = uint32_t(index/m) % (n+1);
+    uint32_t left = uint32_t(pow(2, d - i + 1) * k);
+    if(box != n){
+      output[m*n*left + m*box + r] = input[index];
+    }
+  }
+}
+
+// This function was newly added by the authors of cuparmesan
+template <typename T>
+__host__ void host_copy_from_local(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input,
+                            uint32_t i, uint32_t d,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int n = sqrt(input_lwe_ciphertext_count);
+  int output_lwe_ciphertext_count = pow(2, i) * (n+1);
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = output_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  copy_from_local<<<grid, thds, 0, *stream>>>(output, input, i, d, num_entries, lwe_size, n);
+  cudaStreamSynchronize(*stream);
+}
+
+#endif // CUDA_ADD_H
+
+// This function was newly added by the authors of cuparmesan
+template <typename T>
+__global__ void copy_from_local_for_sign(T *output, T *input, uint32_t i, uint32_t d,
+                         uint32_t num_entries, uint32_t m, uint32_t n) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    uint32_t r = uint32_t(index%m);
+    uint32_t k = uint32_t(index/m);
+    uint32_t left = pow(2, d - i + 1) * k;
+    output[m*left + r] = input[index];
+  }
+}
+
+// This function was newly added by the authors of cuparmesan
+template <typename T>
+__host__ void host_copy_from_local_for_sign(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input,
+                            uint32_t i, uint32_t d,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int n = input_lwe_ciphertext_count;
+  int output_lwe_ciphertext_count = pow(2, i);
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = output_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  copy_from_local_for_sign<<<grid, thds, 0, *stream>>>(output, input, i, d, num_entries, lwe_size, n);
+
+  cudaStreamSynchronize(*stream);
+}
diff --git a/concrete-cuda/cuda/src/and.cu b/concrete-cuda/cuda/src/and.cu
new file mode 100644
index 00000000..b455a76d
--- /dev/null
+++ b/concrete-cuda/cuda/src/and.cu
@@ -0,0 +1,15 @@
+// This file was newly added by the authors of cuparmesan
+#include "and.cuh"
+
+void cuda_and_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_and(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                static_cast<uint64_t *>(lwe_array_in_2), input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
diff --git a/concrete-cuda/cuda/src/and.cuh b/concrete-cuda/cuda/src/and.cuh
new file mode 100644
index 00000000..5ee07c7e
--- /dev/null
+++ b/concrete-cuda/cuda/src/and.cuh
@@ -0,0 +1,46 @@
+// This file was newly added by the authors of cuparmesan
+#ifndef CUDA_ADD_H
+#define CUDA_ADD_H
+
+#ifdef __CDT_PARSER__
+#undef __CUDA_RUNTIME_H__
+#include <cuda_runtime.h>
+#include <helper_cuda.h>
+#endif
+
+#include "linear_algebra.h"
+#include "utils/kernel_dimensions.cuh"
+
+template <typename T>
+__global__ void and_3xy(T *output, T *input_1, T *input_2,
+                         uint32_t num_entries, uint32_t m, uint32_t n) {
+
+  uint32_t index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    uint32_t r = uint32_t(index%m);
+    uint32_t i = uint32_t(index/m);
+    uint32_t idx_x = uint32_t(i%n);
+    uint32_t idx_y = uint32_t(i/n);
+    output[index] = (uint32_t)3 * input_1[m * idx_x + r] + input_2[m * idx_y + r];
+  }
+}
+
+template <typename T>
+__host__ void host_and(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input_1, T *input_2,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int n = input_lwe_ciphertext_count;
+  int num_entries = n * n * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  and_3xy<<<grid, thds, 0, *stream>>>(output, input_1, input_2, num_entries, lwe_size, n);
+  cudaStreamSynchronize(*stream);
+}
+
+#endif
diff --git a/concrete-cuda/cuda/src/bootstrap_amortized.cuh b/concrete-cuda/cuda/src/bootstrap_amortized.cuh
index 2cde4af0..007bd481 100644
--- a/concrete-cuda/cuda/src/bootstrap_amortized.cuh
+++ b/concrete-cuda/cuda/src/bootstrap_amortized.cuh
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 #ifdef __CDT_PARSER__
 #undef __CUDA_RUNTIME_H__
 #include <cuda_runtime.h>
@@ -187,20 +188,20 @@ __global__ void device_bootstrap_amortized(
 
       // Get the bootstrapping key piece necessary for the multiplication
       // It is already in the Fourier domain
-      auto bsk_mask_slice = PolynomialFourier<double2, params>(
+      auto bsk_mask_slice =
           get_ith_mask_kth_block(bootstrapping_key, iteration, 0, level,
-                                 polynomial_size, 1, level_count));
-      auto bsk_body_slice = PolynomialFourier<double2, params>(
+                                 polynomial_size, 1, level_count);
+      auto bsk_body_slice =
           get_ith_body_kth_block(bootstrapping_key, iteration, 0, level,
-                                 polynomial_size, 1, level_count));
+                                 polynomial_size, 1, level_count);
 
       synchronize_threads_in_block();
 
       // Perform the coefficient-wise product with the two pieces of
       // bootstrapping key
-      polynomial_product_accumulate_in_fourier_domain(
+      polynomial_product_accumulate_in_fourier_domain<params, double2>(
           mask_res_fft, accumulator_fft, bsk_mask_slice);
-      polynomial_product_accumulate_in_fourier_domain(
+      polynomial_product_accumulate_in_fourier_domain<params, double2>(
           body_res_fft, accumulator_fft, bsk_body_slice);
 
       synchronize_threads_in_block();
@@ -216,18 +217,18 @@ __global__ void device_bootstrap_amortized(
 
       correction_direct_fft_inplace<params>(accumulator_fft);
 
-      auto bsk_mask_slice_2 = PolynomialFourier<double2, params>(
+      auto bsk_mask_slice_2 =
           get_ith_mask_kth_block(bootstrapping_key, iteration, 1, level,
-                                 polynomial_size, 1, level_count));
-      auto bsk_body_slice_2 = PolynomialFourier<double2, params>(
+                                 polynomial_size, 1, level_count);
+      auto bsk_body_slice_2 =
           get_ith_body_kth_block(bootstrapping_key, iteration, 1, level,
-                                 polynomial_size, 1, level_count));
+                                 polynomial_size, 1, level_count);
 
       synchronize_threads_in_block();
 
-      polynomial_product_accumulate_in_fourier_domain(
+      polynomial_product_accumulate_in_fourier_domain<params, double2>(
           mask_res_fft, accumulator_fft, bsk_mask_slice_2);
-      polynomial_product_accumulate_in_fourier_domain(
+      polynomial_product_accumulate_in_fourier_domain<params, double2>(
           body_res_fft, accumulator_fft, bsk_body_slice_2);
     }
 
diff --git a/concrete-cuda/cuda/src/bootstrap_low_latency.cuh b/concrete-cuda/cuda/src/bootstrap_low_latency.cuh
index 8ebe7a2e..f3001511 100644
--- a/concrete-cuda/cuda/src/bootstrap_low_latency.cuh
+++ b/concrete-cuda/cuda/src/bootstrap_low_latency.cuh
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 #ifdef __CDT_PARSER__
 #undef __CUDA_RUNTIME_H__
 #include <cuda_runtime.h>
@@ -51,12 +52,12 @@ mul_ggsw_glwe(Torus *accumulator, double2 *fft, int16_t *glwe_decomposed,
   // needed to perform the external product in this block (corresponding to
   // the same decomposition level)
 
-  auto bsk_mask_slice = PolynomialFourier<double2, params>(
+  auto bsk_mask_slice =
       get_ith_mask_kth_block(bootstrapping_key, iteration, blockIdx.y,
-                             blockIdx.x, polynomial_size, 1, level_count));
-  auto bsk_body_slice = PolynomialFourier<double2, params>(
+                             blockIdx.x, polynomial_size, 1, level_count);
+  auto bsk_body_slice =
       get_ith_body_kth_block(bootstrapping_key, iteration, blockIdx.y,
-                             blockIdx.x, polynomial_size, 1, level_count));
+                             blockIdx.x, polynomial_size, 1, level_count);
 
   // Perform the matrix multiplication between the GGSW and the GLWE,
   // each block operating on a single level for mask and body
@@ -77,7 +78,7 @@ mul_ggsw_glwe(Torus *accumulator, double2 *fft, int16_t *glwe_decomposed,
 
   // first product
   for (int i = 0; i < params::opt / 2; i++) {
-    first_processed_acc[tid] = fft[tid] * first_processed_bsk.m_values[tid];
+    first_processed_acc[tid] = fft[tid] * first_processed_bsk[tid];
     tid += params::degree / params::opt;
   }
 
@@ -85,7 +86,7 @@ mul_ggsw_glwe(Torus *accumulator, double2 *fft, int16_t *glwe_decomposed,
   tid = threadIdx.x;
   // second product
   for (int i = 0; i < params::opt / 2; i++) {
-    second_processed_acc[tid] += fft[tid] * second_processed_bsk.m_values[tid];
+    second_processed_acc[tid] += fft[tid] * second_processed_bsk[tid];
     tid += params::degree / params::opt;
   }
 
diff --git a/concrete-cuda/cuda/src/copy_at.cu b/concrete-cuda/cuda/src/copy_at.cu
new file mode 100644
index 00000000..30d4acd9
--- /dev/null
+++ b/concrete-cuda/cuda/src/copy_at.cu
@@ -0,0 +1,41 @@
+// This file was newly added by the authors of cuparmesan
+#include "copy_at.cuh"
+
+void cuda_set_at_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_set_at(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                i, input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+void cuda_copy_at_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_copy_at(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                i, input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+void cuda_copy_n_at_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t i,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_copy_n_at(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                i, input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
diff --git a/concrete-cuda/cuda/src/copy_at.cuh b/concrete-cuda/cuda/src/copy_at.cuh
new file mode 100644
index 00000000..1edf9b54
--- /dev/null
+++ b/concrete-cuda/cuda/src/copy_at.cuh
@@ -0,0 +1,103 @@
+// This file was newly added by the authors of cuparmesan
+#ifndef CUDA_ADD_H
+#define CUDA_ADD_H
+
+#ifdef __CDT_PARSER__
+#undef __CUDA_RUNTIME_H__
+#include <cuda_runtime.h>
+#include <helper_cuda.h>
+#endif
+
+#include "linear_algebra.h"
+#include "utils/kernel_dimensions.cuh"
+
+template <typename T>
+__global__ void copy_at(T *output, T *input, uint32_t i,
+                         uint32_t num_entries, uint32_t lwe_size) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    output[index] = input[lwe_size*i + index];
+  }
+}
+
+template <typename T>
+__host__ void host_copy_at(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input,
+                            uint32_t i,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  copy_at<<<grid, thds, 0, *stream>>>(output, input, i, num_entries, lwe_size);
+  cudaStreamSynchronize(*stream);
+}
+
+template <typename T>
+__global__ void set_at(T *output, T *input, uint32_t i,
+                         uint32_t num_entries, uint32_t lwe_size) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    output[lwe_size*i + index] = input[index];
+  }
+}
+
+template <typename T>
+__host__ void host_set_at(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input,
+                            uint32_t i,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  set_at<<<grid, thds, 0, *stream>>>(output, input, i, num_entries, lwe_size);
+
+  cudaStreamSynchronize(*stream);
+}
+
+template <typename T>
+__global__ void copy_n_at(T *output, T *input_1, uint32_t i,
+                         uint32_t num_entries, uint32_t lwe_size, uint32_t n) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    output[index] = input_1[lwe_size*n*i + index];
+  }
+}
+
+template <typename T>
+__host__ void host_copy_n_at(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input_1,
+                            uint32_t i,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int n = sqrt(input_lwe_ciphertext_count);
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = n * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  copy_n_at<<<grid, thds, 0, *stream>>>(output, input_1, i, num_entries, lwe_size, n);
+
+  cudaStreamSynchronize(*stream);
+}
+
+#endif
diff --git a/concrete-cuda/cuda/src/max.cu b/concrete-cuda/cuda/src/max.cu
new file mode 100644
index 00000000..76a5d629
--- /dev/null
+++ b/concrete-cuda/cuda/src/max.cu
@@ -0,0 +1,30 @@
+// This file was newly added by the authors of cuparmesan
+#include "max.cuh"
+
+void cuda_extend_xy_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       void *lwe_array_in_3,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_extend_xy(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                static_cast<uint64_t *>(lwe_array_in_2),
+                static_cast<uint64_t *>(lwe_array_in_3),
+                input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+void cuda_merge_xy_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in,
+                                       uint32_t output_lwe_dimension,
+                                       uint32_t output_lwe_ciphertext_count) {
+
+  host_merge_xy(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in),
+                output_lwe_dimension,
+                output_lwe_ciphertext_count);
+}
diff --git a/concrete-cuda/cuda/src/max.cuh b/concrete-cuda/cuda/src/max.cuh
new file mode 100644
index 00000000..f0d7fba1
--- /dev/null
+++ b/concrete-cuda/cuda/src/max.cuh
@@ -0,0 +1,73 @@
+// This file was newly added by the authors of cuparmesan
+#ifndef CUDA_ADD_H
+#define CUDA_ADD_H
+
+#ifdef __CDT_PARSER__
+#undef __CUDA_RUNTIME_H__
+#include <cuda_runtime.h>
+#include <helper_cuda.h>
+#endif
+
+#include "linear_algebra.h"
+#include "utils/kernel_dimensions.cuh"
+
+template <typename T>
+__global__ void extend_xy(T *output, T *x, T *y, T *s,
+                         uint32_t num_entries, uint32_t m, uint32_t n) {
+  uint32_t index = blockIdx.x * blockDim.x + threadIdx.x;
+  uint32_t r = index % m;
+  if (index < n * m) {
+    output[index] = x[index] + 2 * s[r];
+  } else if (index < num_entries) {
+    output[index] = y[index - n*m] - 2 * s[r];
+  }
+}
+
+template <typename T>
+__host__ void host_extend_xy(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input_1,
+                            T *input_2,
+                            T *input_3,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int n = input_lwe_ciphertext_count;
+  int num_entries = 2 * n * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  extend_xy<<<grid, thds, 0, *stream>>>(output, input_1, input_2, input_3, num_entries, lwe_size, n);
+  cudaStreamSynchronize(*stream);
+}
+
+template <typename T>
+__global__ void merge_xy(T *output, T *input,
+                         uint32_t num_entries, uint32_t m, uint32_t n) {
+  uint32_t index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    output[index] = input[index] + input[n*m + index];
+  }
+}
+
+template <typename T>
+__host__ void host_merge_xy(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input,
+                            uint32_t output_lwe_dimension,
+                            uint32_t output_lwe_ciphertext_count) {
+  cudaSetDevice(gpu_index);
+  int lwe_size = output_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int n = output_lwe_ciphertext_count;
+  int num_entries = n * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  merge_xy<<<grid, thds, 0, *stream>>>(output, input, num_entries, lwe_size, n);
+  cudaStreamSynchronize(*stream);
+}
+
+#endif // CUDA_ADD_H
diff --git a/concrete-cuda/cuda/src/multbyconst.cu b/concrete-cuda/cuda/src/multbyconst.cu
new file mode 100644
index 00000000..381e6ba5
--- /dev/null
+++ b/concrete-cuda/cuda/src/multbyconst.cu
@@ -0,0 +1,15 @@
+// This file was newly added by the authors of cuparmesan
+#include "multbyconst.cuh"
+
+void cuda_mult_by_const_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t k,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_multbyconst(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                k, input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
diff --git a/concrete-cuda/cuda/src/multbyconst.cuh b/concrete-cuda/cuda/src/multbyconst.cuh
new file mode 100644
index 00000000..2b11d39d
--- /dev/null
+++ b/concrete-cuda/cuda/src/multbyconst.cuh
@@ -0,0 +1,45 @@
+// This file was newly added by the authors of cuparmesan
+#ifndef CUDA_ADD_H
+#define CUDA_ADD_H
+
+#ifdef __CDT_PARSER__
+#undef __CUDA_RUNTIME_H__
+#include <cuda_runtime.h>
+#include <helper_cuda.h>
+#endif
+
+#include "linear_algebra.h"
+#include "utils/kernel_dimensions.cuh"
+
+template <typename T>
+__global__ void multbyconst(T *output, T *input_1, uint32_t k,
+                         uint32_t num_entries) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    output[index] = input_1[index] * k;
+  }
+}
+
+template <typename T>
+__host__ void host_multbyconst(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input_1,
+                            uint32_t k,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = input_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  multbyconst<<<grid, thds, 0, *stream>>>(output, input_1, k, num_entries);
+
+  cudaStreamSynchronize(*stream);
+}
+
+#endif // CUDA_ADD_H
diff --git a/concrete-cuda/cuda/src/negation.cu b/concrete-cuda/cuda/src/negation.cu
new file mode 100644
index 00000000..0757f401
--- /dev/null
+++ b/concrete-cuda/cuda/src/negation.cu
@@ -0,0 +1,23 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
+#include "negation.cuh"
+
+void cuda_negate_lwe_ciphertext_vector_32(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          void *lwe_array_in,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count) {
+
+  host_negation(v_stream, gpu_index, static_cast<uint32_t *>(lwe_array_out),
+                static_cast<uint32_t *>(lwe_array_in), input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+void cuda_negate_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          void *lwe_array_in,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count) {
+
+  host_negation(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in), input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
diff --git a/concrete-cuda/cuda/src/negation.cuh b/concrete-cuda/cuda/src/negation.cuh
new file mode 100644
index 00000000..c281700e
--- /dev/null
+++ b/concrete-cuda/cuda/src/negation.cuh
@@ -0,0 +1,47 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
+#ifndef CUDA_NEGATE_H
+#define CUDA_NEGATE_H
+
+#ifdef __CDT_PARSER__
+#undef __CUDA_RUNTIME_H__
+#include <cuda_runtime.h>
+#include <helper_cuda.h>
+#endif
+
+#include "linear_algebra.h"
+#include "utils/kernel_dimensions.cuh"
+
+// This function was modified by the authors of cuparmesan
+template <typename T>
+__global__ void negation(T *output, T *input, uint32_t num_entries) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x; // This line was modified by the authors of cuparmesan
+  if (index < num_entries) { // This line was modified by the authors of cuparmesan
+    // Here we take advantage of the wrapping behaviour of uint
+    output[index] = -input[index];
+  }
+}
+
+template <typename T>
+__host__ void host_negation(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input, uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  // lwe_size includes the presence of the body
+  // whereas lwe_dimension is the number of elements in the mask
+  int lwe_size = input_lwe_dimension + 1;
+  // Create a 1-dimensional grid of threads
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = input_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  negation<<<grid, thds, 0, *stream>>>(output, input, num_entries);
+
+  cudaStreamSynchronize(*stream);
+}
+
+#endif // CUDA_NEGATE_H
diff --git a/concrete-cuda/cuda/src/negation_inplace.cu b/concrete-cuda/cuda/src/negation_inplace.cu
new file mode 100644
index 00000000..717a3892
--- /dev/null
+++ b/concrete-cuda/cuda/src/negation_inplace.cu
@@ -0,0 +1,22 @@
+// This file was newly added by the authors of cuparmesan
+#include "negation_inplace.cuh"
+
+void cuda_negate_lwe_ciphertext_vector_32_inplace(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count) {
+
+  host_negation_inplace(v_stream, gpu_index, static_cast<uint32_t *>(lwe_array_out),
+                input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+void cuda_negate_lwe_ciphertext_vector_64_inplace(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count) {
+
+  host_negation_inplace(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
diff --git a/concrete-cuda/cuda/src/negation_inplace.cuh b/concrete-cuda/cuda/src/negation_inplace.cuh
new file mode 100644
index 00000000..571e941f
--- /dev/null
+++ b/concrete-cuda/cuda/src/negation_inplace.cuh
@@ -0,0 +1,42 @@
+// This file was newly added by the authors of cuparmesan
+#ifndef CUDA_NEGATE_H
+#define CUDA_NEGATE_H
+
+#ifdef __CDT_PARSER__
+#undef __CUDA_RUNTIME_H__
+#include <cuda_runtime.h>
+#include <helper_cuda.h>
+#endif
+
+#include "linear_algebra.h"
+#include "utils/kernel_dimensions.cuh"
+
+template <typename T>
+__global__ void negation_inplace(T *output, uint32_t num_entries) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    output[index] = -output[index];
+  }
+}
+
+template <typename T>
+__host__ void host_negation_inplace(void *v_stream, uint32_t gpu_index, T *output,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = input_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  negation_inplace<<<grid, thds, 0, *stream>>>(output, num_entries);
+
+  cudaStreamSynchronize(*stream);
+}
+
+#endif
diff --git a/concrete-cuda/cuda/src/polynomial/polynomial.cuh b/concrete-cuda/cuda/src/polynomial/polynomial.cuh
index df770d2e..40799d6e 100644
--- a/concrete-cuda/cuda/src/polynomial/polynomial.cuh
+++ b/concrete-cuda/cuda/src/polynomial/polynomial.cuh
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 #ifndef CNCRT_POLYNOMIAL_H
 #define CNCRT_POLYNOMIAL_H
 
@@ -25,7 +26,6 @@ public:
   uint32_t m_size;
   __device__ ExtraMemory(uint32_t size) : m_size(size) {}
 };
-template <typename T, class params> class PolynomialFourier;
 
 template <typename T, class params> class Polynomial;
 
@@ -41,11 +41,6 @@ public:
   __device__ VectorPolynomial(T *data, uint32_t num_polynomials)
       : m_data(data), m_num_polynomials(num_polynomials) {}
 
-  __device__ VectorPolynomial(SharedMemory &shmem, uint32_t num_polynomials)
-      : m_num_polynomials(num_polynomials) {
-    shmem.get_allocation(&m_data, m_num_polynomials * params::degree);
-  }
-
   __device__ VectorPolynomial<T, params> get_chunk(int chunk_num,
                                                    int chunk_size) {
     int pos = chunk_num * chunk_size;
@@ -87,22 +82,6 @@ public:
     synchronize_threads_in_block();
   }
 
-  __device__ void copy_into_ith_polynomial(PolynomialFourier<T, params> &source,
-                                           int i) {
-    int tid = threadIdx.x;
-    int begin = i * (params::degree / 2 + 1);
-#pragma unroll
-    for (int i = 0; i < params::opt / 2; i++) {
-      this->m_data[tid + begin] = source.m_values[tid];
-      tid = tid + params::degree / params::opt;
-    }
-
-    if (threadIdx.x == 0) {
-      this->m_data[params::degree / 2 + begin] =
-          source.m_values[params::degree / 2];
-    }
-  }
-
   __device__ void split_into_polynomials(Polynomial<T, params> &first,
                                          Polynomial<T, params> &second) {
     int tid = threadIdx.x;
@@ -115,77 +94,6 @@ public:
   }
 };
 
-template <typename T, class params> class PolynomialFourier {
-public:
-  T *m_values;
-  uint32_t degree;
-
-  __device__ __host__ PolynomialFourier(T *m_values) : m_values(m_values) {}
-
-  __device__ PolynomialFourier(SharedMemory &shmem) : degree(degree) {
-    shmem.get_allocation(&this->m_values, params::degree);
-  }
-
-  __device__ PolynomialFourier(SharedMemory &shmem, ExtraMemory extra_memory)
-      : degree(degree) {
-    shmem.get_allocation(&this->m_values, params::degree + extra_memory.m_size);
-  }
-  __device__ PolynomialFourier(SharedMemory &shmem, uint32_t degree)
-      : degree(degree) {
-    shmem.get_allocation(&this->m_values, degree);
-  }
-
-  __host__ PolynomialFourier(DeviceMemory &dmem, int device) : degree(degree) {
-    dmem.get_allocation(&this->m_values, params::degree, device);
-  }
-
-  __device__ char *reuse_memory() { return (char *)m_values; }
-  __device__ void copy_from(PolynomialFourier<T, params> &source, int begin) {
-    int tid = threadIdx.x;
-#pragma unroll
-    for (int i = 0; i < params::opt; i++) {
-      this->m_values[tid + begin] = source.m_values[tid];
-      tid = tid + params::degree / params::opt;
-    }
-  }
-  __device__ void fill_with(T value) {
-    int tid = threadIdx.x;
-#pragma unroll
-    for (int i = 0; i < params::opt; i++) {
-      m_values[tid] = value;
-      tid += params::degree / params::opt;
-    }
-  }
-
-  __device__ void swap_quarters_inplace() {
-    int tid = threadIdx.x;
-    int s1 = params::quarter;
-    int s2 = params::three_quarters;
-
-    T tmp = m_values[s2 + tid];
-    m_values[s2 + tid] = m_values[s1 + tid];
-    m_values[s1 + tid] = tmp;
-  }
-
-  __device__ void add_polynomial_inplace(VectorPolynomial<T, params> &source,
-                                         int polynomial_number) {
-    int tid = threadIdx.x;
-    int begin = polynomial_number * (params::degree / 2 + 1);
-#pragma unroll
-    for (int i = 0; i < params::opt / 2; i++) {
-      this->m_values[tid] += source.m_data[tid + begin];
-      tid = tid + params::degree / params::opt;
-    }
-
-    if (threadIdx.x == 0) {
-      this->m_values[params::degree / 2] +=
-          source.m_data[params::degree / 2 + begin];
-    }
-  }
-
-  __device__ T &operator[](int i) { return m_values[i]; }
-};
-
 template <typename T, class params> class Polynomial {
 public:
   T *coefficients;
@@ -197,10 +105,6 @@ public:
   __device__ Polynomial(char *memory, uint32_t degree)
       : coefficients((T *)memory), degree(degree) {}
 
-  __device__ Polynomial(SharedMemory &shmem, uint32_t degree) : degree(degree) {
-    shmem.get_allocation(&this->coefficients, degree);
-  }
-
   __host__ Polynomial(DeviceMemory &dmem, uint32_t degree, int device)
       : degree(degree) {
     dmem.get_allocation(&this->coefficients, params::degree, device);
@@ -386,28 +290,6 @@ public:
     }
   }
 
-  __device__ void
-  to_complex_compressed(PolynomialFourier<double2, params> &dest) {
-
-    int tid = threadIdx.x;
-#pragma unroll
-    for (int i = 0; i < params::opt / 2; i++) {
-      dest.m_values[tid].x = (double)coefficients[2 * tid];
-      dest.m_values[tid].y = (double)coefficients[2 * tid + 1];
-      tid += params::degree / params::opt;
-    }
-  }
-
-  __device__ void to_complex(PolynomialFourier<double2, params> &dest) {
-    int tid = threadIdx.x;
-#pragma unroll
-    for (int i = 0; i < params::opt; i++) {
-      dest.m_values[tid].x = (double)coefficients[tid];
-      dest.m_values[tid].y = 0.0;
-      tid += params::degree / params::opt;
-    }
-  }
-
   __device__ void multiply_by_scalar_inplace(T scalar) {
     int tid = threadIdx.x;
     const int grid_dim = blockDim.x;
@@ -506,30 +388,8 @@ public:
   __device__ Vector(T *elements, uint32_t size)
       : m_data(elements), m_size(size) {}
 
-  template <typename V>
-  __device__ Vector(SharedMemory &shmem, V src, int size) : m_size(size) {
-    shmem.get_allocation(&m_data, m_size);
-    int tid = threadIdx.x;
-#pragma unroll
-    for (int i = 0; i < params::opt && tid < m_size; i++) {
-      if (tid > m_size)
-        continue;
-      m_data[tid] = src[tid];
-      tid += params::degree / params::opt;
-    }
-  }
-
-  __device__ Vector(SharedMemory &shmem, uint32_t size) : m_size(size) {
-    shmem.get_allocation(&m_data, m_size);
-  }
-
   __host__ Vector() {}
 
-  __host__ Vector(DeviceMemory &dmem, uint32_t size, int device)
-      : m_size(size) {
-    dmem.get_allocation(&m_data, m_size, device);
-  }
-
   __device__ T &operator[](int i) { return m_data[i]; }
 
   __device__ Vector<T, params> get_chunk(int chunk_num, int chunk_size) {
diff --git a/concrete-cuda/cuda/src/polynomial/polynomial_math.cuh b/concrete-cuda/cuda/src/polynomial/polynomial_math.cuh
index a36667b9..538bc800 100644
--- a/concrete-cuda/cuda/src/polynomial/polynomial_math.cuh
+++ b/concrete-cuda/cuda/src/polynomial/polynomial_math.cuh
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 #ifndef CNCRT_POLYNOMIAL_MATH_H
 #define CNCRT_POLYNOMIAL_MATH_H
 
@@ -14,26 +15,9 @@ __device__ void sub_polynomial(FT *result, FT *first, FT *second) {
   }
 }
 
-template <class params, typename FT>
-__device__ void polynomial_product_in_fourier_domain(FT *result, FT *first,
-                                                     FT *second) {
-  int tid = threadIdx.x;
-  for (int i = 0; i < params::opt / 2; i++) {
-    result[tid] = first[tid] * second[tid];
-    tid += params::degree / params::opt;
-  }
-
-  if (threadIdx.x == 0) {
-    result[params::degree / 2] =
-        first[params::degree / 2] * second[params::degree / 2];
-  }
-}
-
-template <class params, typename FT>
-__device__ void
-polynomial_product_in_fourier_domain(PolynomialFourier<FT, params> &result,
-                                     PolynomialFourier<FT, params> &first,
-                                     PolynomialFourier<FT, params> &second) {
+template <class params, typename T>
+__device__ void polynomial_product_in_fourier_domain(T *result, T *first,
+                                                     T *second) {
   int tid = threadIdx.x;
   for (int i = 0; i < params::opt / 2; i++) {
     result[tid] = first[tid] * second[tid];
@@ -46,32 +30,6 @@ polynomial_product_in_fourier_domain(PolynomialFourier<FT, params> &result,
   }
 }
 
-template <class params, typename FT>
-__device__ void polynomial_product_accumulate_in_fourier_domain(
-    PolynomialFourier<FT, params> &result, PolynomialFourier<FT, params> &first,
-    PolynomialFourier<FT, params> &second) {
-  int tid = threadIdx.x;
-  for (int i = 0; i < params::opt / 2; i++) {
-    result[tid] += first[tid] * second[tid];
-    tid += params::degree / params::opt;
-  }
-
-  if (threadIdx.x == 0) {
-    result[params::degree / 2] +=
-        first[params::degree / 2] * second[params::degree / 2];
-  }
-}
-
-template <class params, typename FT>
-__device__ void polynomial_product_accumulate_in_fourier_domain(
-    FT *result, FT *first, PolynomialFourier<FT, params> &second) {
-  int tid = threadIdx.x;
-  for (int i = 0; i < params::opt / 2; i++) {
-    result[tid] += first[tid] * second.m_values[tid];
-    tid += params::degree / params::opt;
-  }
-}
-
 template <class params, typename T>
 __device__ void polynomial_product_accumulate_in_fourier_domain(T *result,
                                                                 T *first,
diff --git a/concrete-cuda/cuda/src/reduction.cu b/concrete-cuda/cuda/src/reduction.cu
new file mode 100644
index 00000000..6966b8dd
--- /dev/null
+++ b/concrete-cuda/cuda/src/reduction.cu
@@ -0,0 +1,175 @@
+// This file was newly added by the authors of cuparmesan
+#include "reduction.cuh"
+
+/* Perform a multiplication on a batch of input LWE ciphertexts (yotei)
+ *
+ *  - lwe_array_out: output batch of num_samples bootstrapped ciphertexts c =
+ * (a0,..an-1,b) where n is the LWE dimension
+ *  - lut_vector: should hold as many test vectors of size polynomial_size
+ * as there are input ciphertexts, but actually holds
+ * num_lut_vectors vectors to reduce memory usage
+ *  - lut_vector_indexes: stores the index corresponding to
+ * which test vector to use for each sample in
+ * lut_vector
+ *  - lwe_array_in: input batch of num_samples LWE ciphertexts, containing n
+ * mask values + 1 body value
+ *  - bootstrapping_key: RGSW encryption of the LWE secret key sk1
+ * under secret key sk2
+ * bsk = Z + sk1 H
+ * where H is the gadget matrix and Z is a matrix (k+1).l
+ * containing GLWE encryptions of 0 under sk2.
+ * bsk is thus a tensor of size (k+1)^2.l.N.n
+ * where l is the number of decomposition levels and
+ * k is the GLWE dimension, N is the polynomial size for
+ * GLWE. The polynomial size for GLWE and the test vector
+ * are the same because they have to be in the same ring
+ * to be multiplied.
+ * Note: it is necessary to generate (k+1).k.l.N.n
+ * uniformly random coefficients for the zero encryptions
+ * - input_lwe_dimension: size of the Torus vector used to encrypt the input
+ * LWE ciphertexts - referred to as n above (~ 600)
+ * - polynomial_size: size of the test polynomial (test vector) and size of the
+ * GLWE polynomial (~1024)
+ * - base_log: log base used for the gadget matrix - B = 2^base_log (~8)
+ * - level_count: number of decomposition levels in the gadget matrix (~4)
+ * - num_samples: number of encrypted input messages
+ * - num_lut_vectors: parameter to set the actual number of test vectors to be
+ * used
+ * - q: number of bytes in the integer representation (32 or 64)
+ *
+ * This function calls a wrapper to a device kernel that performs the
+ * bootstrapping:
+ * 	- the kernel is templatized based on integer discretization and
+ * polynomial degree
+ * 	- num_samples blocks of threads are launched, where each thread is going
+ * to handle one or more polynomial coefficients at each stage:
+ * 		- perform the blind rotation
+ * 		- round the result
+ * 		- decompose into level_count levels, then for each level:
+ * 		  - switch to the FFT domain
+ * 		  - multiply with the bootstrapping key
+ * 		  - come back to the coefficients representation
+ * 	- between each stage a synchronization of the threads is necessary
+ * 	- in case the device has enough shared memory, temporary arrays used for
+ * the different stages (accumulators) are stored into the shared memory
+ * 	- the accumulators serve to combine the results for all decomposition
+ * levels
+ * 	- the constant memory (64K) is used for storing the roots of identity
+ * values for the FFT
+ */
+
+void cuda_paralell_reduction_32(
+    void *v_stream, void *lwe_array_out, void *lut_vector,
+    void *lut_vector_indexes, void *lwe_array_in, void *bootstrapping_key,
+    uint32_t lwe_dimension, uint32_t glwe_dimension, uint32_t polynomial_size,
+    uint32_t base_log, uint32_t level_count, uint32_t num_samples,
+    uint32_t num_lut_vectors, uint32_t lwe_idx, uint32_t max_shared_memory) {
+
+  assert(
+      ("Error (GPU amortized PBS): base log should be <= 16", base_log <= 16));
+  assert(("Error (GPU amortized PBS): glwe_dimension should be equal to 1",
+          glwe_dimension == 1));
+  assert(("Error (GPU amortized PBS): polynomial size should be one of 512, "
+          "1024, 2048, 4096, 8192",
+          polynomial_size == 512 || polynomial_size == 1024 ||
+              polynomial_size == 2048 || polynomial_size == 4096 ||
+              polynomial_size == 8192));
+
+  switch (polynomial_size) {
+  case 512:
+    host_paralell_reduction<uint32_t, Degree<512>>(
+        v_stream, (uint32_t *)lwe_array_out, (uint32_t *)lut_vector,
+        (uint32_t *)lut_vector_indexes, (uint32_t *)lwe_array_in,
+        (double2 *)bootstrapping_key, lwe_dimension, polynomial_size, base_log,
+        level_count, num_samples, num_lut_vectors, lwe_idx, max_shared_memory);
+    break;
+  case 1024:
+    host_paralell_reduction<uint32_t, Degree<1024>>(
+        v_stream, (uint32_t *)lwe_array_out, (uint32_t *)lut_vector,
+        (uint32_t *)lut_vector_indexes, (uint32_t *)lwe_array_in,
+        (double2 *)bootstrapping_key, lwe_dimension, polynomial_size, base_log,
+        level_count, num_samples, num_lut_vectors, lwe_idx, max_shared_memory);
+    break;
+  case 2048:
+    host_paralell_reduction<uint32_t, Degree<2048>>(
+        v_stream, (uint32_t *)lwe_array_out, (uint32_t *)lut_vector,
+        (uint32_t *)lut_vector_indexes, (uint32_t *)lwe_array_in,
+        (double2 *)bootstrapping_key, lwe_dimension, polynomial_size, base_log,
+        level_count, num_samples, num_lut_vectors, lwe_idx, max_shared_memory);
+    break;
+  case 4096:
+    host_paralell_reduction<uint32_t, Degree<4096>>(
+        v_stream, (uint32_t *)lwe_array_out, (uint32_t *)lut_vector,
+        (uint32_t *)lut_vector_indexes, (uint32_t *)lwe_array_in,
+        (double2 *)bootstrapping_key, lwe_dimension, polynomial_size, base_log,
+        level_count, num_samples, num_lut_vectors, lwe_idx, max_shared_memory);
+    break;
+  case 8192:
+    host_paralell_reduction<uint32_t, Degree<8192>>(
+        v_stream, (uint32_t *)lwe_array_out, (uint32_t *)lut_vector,
+        (uint32_t *)lut_vector_indexes, (uint32_t *)lwe_array_in,
+        (double2 *)bootstrapping_key, lwe_dimension, polynomial_size, base_log,
+        level_count, num_samples, num_lut_vectors, lwe_idx, max_shared_memory);
+    break;
+  default:
+    break;
+  }
+}
+
+void cuda_paralell_reduction_64(
+    void *v_stream, void *lwe_array_out, void *lut_vector,
+    void *lut_vector_indexes, void *lwe_array_in, void *bootstrapping_key,
+    uint32_t lwe_dimension, uint32_t glwe_dimension, uint32_t polynomial_size,
+    uint32_t base_log, uint32_t level_count, uint32_t num_samples,
+    uint32_t num_lut_vectors, uint32_t lwe_idx, uint32_t max_shared_memory) {
+
+  assert(
+      ("Error (GPU amortized PBS): base log should be <= 16", base_log <= 16));
+  assert(("Error (GPU amortized PBS): glwe_dimension should be equal to 1",
+          glwe_dimension == 1));
+  assert(("Error (GPU amortized PBS): polynomial size should be one of 512, "
+          "1024, 2048, 4096, 8192",
+          polynomial_size == 512 || polynomial_size == 1024 ||
+              polynomial_size == 2048 || polynomial_size == 4096 ||
+              polynomial_size == 8192));
+
+  switch (polynomial_size) {
+  case 512:
+    host_paralell_reduction<uint64_t, Degree<512>>(
+        v_stream, (uint64_t *)lwe_array_out, (uint64_t *)lut_vector,
+        (uint32_t *)lut_vector_indexes, (uint64_t *)lwe_array_in,
+        (double2 *)bootstrapping_key, lwe_dimension, polynomial_size, base_log,
+        level_count, num_samples, num_lut_vectors, lwe_idx, max_shared_memory);
+    break;
+  case 1024:
+    host_paralell_reduction<uint64_t, Degree<1024>>(
+        v_stream, (uint64_t *)lwe_array_out, (uint64_t *)lut_vector,
+        (uint32_t *)lut_vector_indexes, (uint64_t *)lwe_array_in,
+        (double2 *)bootstrapping_key, lwe_dimension, polynomial_size, base_log,
+        level_count, num_samples, num_lut_vectors, lwe_idx, max_shared_memory);
+    break;
+  case 2048:
+    host_paralell_reduction<uint64_t, Degree<2048>>(
+        v_stream, (uint64_t *)lwe_array_out, (uint64_t *)lut_vector,
+        (uint32_t *)lut_vector_indexes, (uint64_t *)lwe_array_in,
+        (double2 *)bootstrapping_key, lwe_dimension, polynomial_size, base_log,
+        level_count, num_samples, num_lut_vectors, lwe_idx, max_shared_memory);
+    break;
+  case 4096:
+    host_paralell_reduction<uint64_t, Degree<4096>>(
+        v_stream, (uint64_t *)lwe_array_out, (uint64_t *)lut_vector,
+        (uint32_t *)lut_vector_indexes, (uint64_t *)lwe_array_in,
+        (double2 *)bootstrapping_key, lwe_dimension, polynomial_size, base_log,
+        level_count, num_samples, num_lut_vectors, lwe_idx, max_shared_memory);
+    break;
+  case 8192:
+    host_paralell_reduction<uint64_t, Degree<8192>>(
+        v_stream, (uint64_t *)lwe_array_out, (uint64_t *)lut_vector,
+        (uint32_t *)lut_vector_indexes, (uint64_t *)lwe_array_in,
+        (double2 *)bootstrapping_key, lwe_dimension, polynomial_size, base_log,
+        level_count, num_samples, num_lut_vectors, lwe_idx, max_shared_memory);
+    break;
+  default:
+    break;
+  }
+}
diff --git a/concrete-cuda/cuda/src/reduction.cuh b/concrete-cuda/cuda/src/reduction.cuh
new file mode 100644
index 00000000..f2c04934
--- /dev/null
+++ b/concrete-cuda/cuda/src/reduction.cuh
@@ -0,0 +1,335 @@
+// This file was newly added by the authors of cuparmesan
+#ifdef __CDT_PARSER__
+#undef __CUDA_RUNTIME_H__
+#include <cuda_runtime.h>
+#include <helper_cuda.h>
+#endif
+
+#ifndef CNCRT_AMORTIZED_PBS_H
+#define CNCRT_AMORTIZED_PBS_H
+
+#include "cooperative_groups.h"
+
+#include "../include/helper_cuda.h"
+#include "bootstrap.h"
+#include "complex/operations.cuh"
+#include "crypto/gadget.cuh"
+#include "crypto/torus.cuh"
+#include "fft/bnsmfft.cuh"
+#include "fft/smfft.cuh"
+#include "fft/twiddles.cuh"
+#include "polynomial/functions.cuh"
+#include "polynomial/parameters.cuh"
+#include "polynomial/polynomial.cuh"
+#include "polynomial/polynomial_math.cuh"
+#include "utils/memory.cuh"
+#include "utils/timer.cuh"
+
+
+/*
+ * Uses shared memory to increase performance
+ *  - lwe_array_out: output batch of num_samples bootstrapped ciphertexts c = (a0,..an-1,b) where n is the LWE dimension
+ *  - lut_vector: should hold as many test vectors of size polynomial_size as there are input ciphertexts, but actually holds num_lut_vectors vectors to reduce memory usage
+ *  - lut_vector_indexes: stores the index corresponding to which test vector to use for each sample in lut_vector
+ *  - lwe_array_in: input batch of num_samples LWE ciphertexts, containing n mask values + 1 body value
+ *  - bootstrapping_key: RGSW encryption of the LWE secret key sk1 under secret key sk2
+ *  - device_mem: pointer to the device's global memory in case we use it (SMD == NOSM or PARTIALSM)
+ *  - lwe_dimension: size of the Torus vector used to encrypt the input LWE ciphertexts - referred to as n above (~ 600)
+ *  - polynomial_size: size of the test polynomial (test vector) and size of the GLWE polynomial (~1024)
+ *  - base_log: log base used for the gadget matrix - B = 2^base_log (~8)
+ *  - level_count: number of decomposition levels in the gadget matrix (~4)
+ *  - gpu_num: index of the current GPU (useful for multi-GPU computations)
+ *  - lwe_idx: equal to the number of samples per gpu x gpu_num
+ *  - device_memory_size_per_sample: amount of global memory to allocate if SMD is not FULLSM
+ */
+
+template <typename Torus, class params, sharedMemDegree SMD>
+__global__ void device_reduce_at(
+    Torus *lwe_array_out, Torus *lut_vector, uint32_t *lut_vector_indexes,
+    Torus *lwe_array_in, double2 *bootstrapping_key, char *device_mem,
+    uint32_t lwe_dimension, uint32_t polynomial_size, uint32_t base_log,
+    uint32_t level_count, uint32_t lwe_idx,
+    size_t device_memory_size_per_sample) {
+
+  extern __shared__ char sharedmem[];
+  char *selected_memory;
+
+  if constexpr (SMD == FULLSM)
+    selected_memory = sharedmem;
+  else
+    selected_memory = &device_mem[blockIdx.x * device_memory_size_per_sample];
+
+  int16_t *accumulator_mask_decomposed = (int16_t *)selected_memory;
+  int16_t *accumulator_body_decomposed =
+      (int16_t *)accumulator_mask_decomposed + polynomial_size;
+  Torus *accumulator_mask = (Torus *)accumulator_body_decomposed +
+                            polynomial_size / (sizeof(Torus) / sizeof(int16_t));
+  Torus *accumulator_body =
+      (Torus *)accumulator_mask + (ptrdiff_t)polynomial_size;
+  Torus *accumulator_mask_rotated =
+      (Torus *)accumulator_body + (ptrdiff_t)polynomial_size;
+  Torus *accumulator_body_rotated =
+      (Torus *)accumulator_mask_rotated + (ptrdiff_t)polynomial_size;
+  double2 *mask_res_fft = (double2 *)accumulator_body_rotated +
+                          polynomial_size / (sizeof(double2) / sizeof(Torus));
+  double2 *body_res_fft =
+      (double2 *)mask_res_fft + (ptrdiff_t)polynomial_size / 2;
+  double2 *accumulator_fft = (double2 *)sharedmem;
+  if constexpr (SMD != PARTIALSM)
+    accumulator_fft =
+        (double2 *)body_res_fft + (ptrdiff_t)(polynomial_size / 2);
+
+  auto block_lwe_array_in = &lwe_array_in[blockIdx.x * (lwe_dimension + 1)];
+  Torus *block_lut_vector =
+      &lut_vector[lut_vector_indexes[lwe_idx + blockIdx.x] * params::degree *
+                  2];
+
+  GadgetMatrix<Torus, params> gadget(base_log, level_count);
+
+  Torus b_hat = rescale_torus_element(
+      block_lwe_array_in[lwe_dimension],
+      2 * params::degree);
+
+  divide_by_monomial_negacyclic_inplace<Torus, params::opt,
+                                        params::degree / params::opt>(
+      accumulator_mask, block_lut_vector, b_hat, false);
+
+  divide_by_monomial_negacyclic_inplace<Torus, params::opt,
+                                        params::degree / params::opt>(
+      accumulator_body, &block_lut_vector[params::degree], b_hat, false);
+
+  for (int iteration = 0; iteration < lwe_dimension; iteration++) {
+    synchronize_threads_in_block();
+
+    Torus a_hat = rescale_torus_element(
+        block_lwe_array_in[iteration],
+        2 * params::degree);
+
+    multiply_by_monomial_negacyclic_and_sub_polynomial<
+        Torus, params::opt, params::degree / params::opt>(
+        accumulator_mask, accumulator_mask_rotated, a_hat);
+
+    multiply_by_monomial_negacyclic_and_sub_polynomial<
+        Torus, params::opt, params::degree / params::opt>(
+        accumulator_body, accumulator_body_rotated, a_hat);
+
+    synchronize_threads_in_block();
+
+    round_to_closest_multiple_inplace<Torus, params::opt,
+                                      params::degree / params::opt>(
+        accumulator_mask_rotated, base_log, level_count);
+
+    round_to_closest_multiple_inplace<Torus, params::opt,
+                                      params::degree / params::opt>(
+        accumulator_body_rotated, base_log, level_count);
+    int pos = threadIdx.x;
+    for (int j = 0; j < params::opt / 2; j++) {
+      mask_res_fft[pos].x = 0;
+      mask_res_fft[pos].y = 0;
+      body_res_fft[pos].x = 0;
+      body_res_fft[pos].y = 0;
+      pos += params::degree / params::opt;
+    }
+
+    for (int level = 0; level < level_count; level++) {
+
+      gadget.decompose_one_level(accumulator_mask_decomposed,
+                                 accumulator_mask_rotated, level);
+
+      gadget.decompose_one_level(accumulator_body_decomposed,
+                                 accumulator_body_rotated, level);
+
+      synchronize_threads_in_block();
+
+      real_to_complex_compressed<int16_t, params>(accumulator_mask_decomposed,
+                                                  accumulator_fft);
+
+      synchronize_threads_in_block();
+      NSMFFT_direct<HalfDegree<params>>(accumulator_fft);
+      synchronize_threads_in_block();
+
+      correction_direct_fft_inplace<params>(accumulator_fft);
+
+      auto bsk_mask_slice =
+          get_ith_mask_kth_block(bootstrapping_key, iteration, 0, level,
+                                 polynomial_size, 1, level_count);
+      auto bsk_body_slice =
+          get_ith_body_kth_block(bootstrapping_key, iteration, 0, level,
+                                 polynomial_size, 1, level_count);
+
+      synchronize_threads_in_block();
+
+      polynomial_product_accumulate_in_fourier_domain<params, double2>(
+          mask_res_fft, accumulator_fft, bsk_mask_slice);
+      polynomial_product_accumulate_in_fourier_domain<params, double2>(
+          body_res_fft, accumulator_fft, bsk_body_slice);
+
+      synchronize_threads_in_block();
+
+      real_to_complex_compressed<int16_t, params>(accumulator_body_decomposed,
+                                                  accumulator_fft);
+      synchronize_threads_in_block();
+
+      NSMFFT_direct<HalfDegree<params>>(accumulator_fft);
+      synchronize_threads_in_block();
+
+      correction_direct_fft_inplace<params>(accumulator_fft);
+
+      auto bsk_mask_slice_2 =
+          get_ith_mask_kth_block(bootstrapping_key, iteration, 1, level,
+                                 polynomial_size, 1, level_count);
+      auto bsk_body_slice_2 =
+          get_ith_body_kth_block(bootstrapping_key, iteration, 1, level,
+                                 polynomial_size, 1, level_count);
+
+      synchronize_threads_in_block();
+
+      polynomial_product_accumulate_in_fourier_domain<params, double2>(
+          mask_res_fft, accumulator_fft, bsk_mask_slice_2);
+      polynomial_product_accumulate_in_fourier_domain<params, double2>(
+          body_res_fft, accumulator_fft, bsk_body_slice_2);
+    }
+
+    if constexpr (SMD == FULLSM || SMD == NOSM) {
+      synchronize_threads_in_block();
+
+      correction_inverse_fft_inplace<params>(mask_res_fft);
+      correction_inverse_fft_inplace<params>(body_res_fft);
+      synchronize_threads_in_block();
+
+      NSMFFT_inverse<HalfDegree<params>>(mask_res_fft);
+      NSMFFT_inverse<HalfDegree<params>>(body_res_fft);
+
+      synchronize_threads_in_block();
+
+      add_to_torus<Torus, params>(mask_res_fft, accumulator_mask);
+      add_to_torus<Torus, params>(body_res_fft, accumulator_body);
+      synchronize_threads_in_block();
+    } else {
+      int tid = threadIdx.x;
+#pragma unroll
+      for (int i = 0; i < params::opt / 2; i++) {
+        accumulator_fft[tid] = mask_res_fft[tid];
+        tid = tid + params::degree / params::opt;
+      }
+      synchronize_threads_in_block();
+
+      correction_inverse_fft_inplace<params>(accumulator_fft);
+      synchronize_threads_in_block();
+
+      NSMFFT_inverse<HalfDegree<params>>(accumulator_fft);
+      synchronize_threads_in_block();
+
+      add_to_torus<Torus, params>(accumulator_fft, accumulator_mask);
+      synchronize_threads_in_block();
+
+      tid = threadIdx.x;
+#pragma unroll
+      for (int i = 0; i < params::opt / 2; i++) {
+        accumulator_fft[tid] = body_res_fft[tid];
+        tid = tid + params::degree / params::opt;
+      }
+      synchronize_threads_in_block();
+
+      correction_inverse_fft_inplace<params>(accumulator_fft);
+      synchronize_threads_in_block();
+
+      NSMFFT_inverse<HalfDegree<params>>(accumulator_fft);
+      synchronize_threads_in_block();
+
+      add_to_torus<Torus, params>(accumulator_fft, accumulator_body);
+      synchronize_threads_in_block();
+    }
+  }
+
+  auto block_lwe_array_out = &lwe_array_out[blockIdx.x * (polynomial_size + 1)];
+  sample_extract_mask<Torus, params>(block_lwe_array_out, accumulator_mask);
+  sample_extract_body<Torus, params>(block_lwe_array_out, accumulator_body);
+}
+
+template <typename Torus, class params>
+__host__ void host_paralell_reduction(
+    void *v_stream, Torus *lwe_array_out, Torus *lut_vector,
+    uint32_t *lut_vector_indexes, Torus *lwe_array_in,
+    double2 *bootstrapping_key, uint32_t input_lwe_dimension,
+    uint32_t polynomial_size, uint32_t base_log, uint32_t level_count,
+    uint32_t input_lwe_ciphertext_count, uint32_t num_lut_vectors,
+    uint32_t lwe_idx, uint32_t max_shared_memory) {
+
+  int SM_FULL = sizeof(Torus) * polynomial_size +
+                sizeof(Torus) * polynomial_size +
+                sizeof(Torus) * polynomial_size +
+                sizeof(Torus) * polynomial_size +
+                sizeof(int16_t) * polynomial_size +
+                sizeof(int16_t) * polynomial_size +
+                sizeof(double2) * polynomial_size / 2 +
+                sizeof(double2) * polynomial_size / 2 +
+                sizeof(double2) * polynomial_size / 2;
+
+  int SM_PART = sizeof(double2) * polynomial_size / 2;
+
+  int DM_PART = SM_FULL - SM_PART;
+
+  int DM_FULL = SM_FULL;
+
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+
+  char *d_mem;
+
+  dim3 grid(input_lwe_ciphertext_count, 1, 1);
+  dim3 thds(polynomial_size / params::opt, 1, 1);
+
+  if (max_shared_memory < SM_PART) {
+    checkCudaErrors(
+        cudaMalloc((void **)&d_mem, DM_FULL * input_lwe_ciphertext_count));
+    device_reduce_at<Torus, params, NOSM><<<grid, thds, 0, *stream>>>(
+        lwe_array_out, lut_vector, lut_vector_indexes, lwe_array_in,
+        bootstrapping_key, d_mem, input_lwe_dimension, polynomial_size,
+        base_log, level_count, lwe_idx, DM_FULL);
+  } else if (max_shared_memory < SM_FULL) {
+    cudaFuncSetAttribute(device_reduce_at<Torus, params, PARTIALSM>,
+                         cudaFuncAttributeMaxDynamicSharedMemorySize, SM_PART);
+    cudaFuncSetCacheConfig(device_reduce_at<Torus, params, PARTIALSM>,
+                           cudaFuncCachePreferShared);
+    checkCudaErrors(
+        cudaMalloc((void **)&d_mem, DM_PART * input_lwe_ciphertext_count));
+    device_reduce_at<Torus, params, PARTIALSM>
+        <<<grid, thds, SM_PART, *stream>>>(
+            lwe_array_out, lut_vector, lut_vector_indexes, lwe_array_in,
+            bootstrapping_key, d_mem, input_lwe_dimension, polynomial_size,
+            base_log, level_count, lwe_idx, DM_PART);
+  } else {
+    checkCudaErrors(cudaFuncSetAttribute(
+        device_reduce_at<Torus, params, FULLSM>,
+        cudaFuncAttributeMaxDynamicSharedMemorySize, SM_FULL));
+    checkCudaErrors(cudaFuncSetCacheConfig(
+        device_reduce_at<Torus, params, FULLSM>,
+        cudaFuncCachePreferShared));
+    checkCudaErrors(cudaMalloc((void **)&d_mem, 0));
+
+    device_reduce_at<Torus, params, FULLSM>
+        <<<grid, thds, SM_FULL, *stream>>>(
+            lwe_array_out, lut_vector, lut_vector_indexes, lwe_array_in,
+            bootstrapping_key, d_mem, input_lwe_dimension, polynomial_size,
+            base_log, level_count, lwe_idx, 0);
+  }
+  cudaStreamSynchronize(*stream);
+  cudaFree(d_mem);
+}
+
+template <typename Torus, class params>
+int cuda_get_pbs_per_gpu(int polynomial_size) {
+
+  int blocks_per_sm = 0;
+  int num_threads = polynomial_size / params::opt;
+  cudaGetDeviceCount(0);
+  cudaDeviceProp device_properties;
+  cudaGetDeviceProperties(&device_properties, 0);
+  cudaOccupancyMaxActiveBlocksPerMultiprocessor(
+      &blocks_per_sm, device_reduce_at<Torus, params>, num_threads,
+      0);
+
+  return device_properties.multiProcessorCount * blocks_per_sm;
+}
+
+#endif
diff --git a/concrete-cuda/cuda/src/rotation.cu b/concrete-cuda/cuda/src/rotation.cu
new file mode 100644
index 00000000..73e81ac3
--- /dev/null
+++ b/concrete-cuda/cuda/src/rotation.cu
@@ -0,0 +1,25 @@
+// This file was newly added by the authors of cuparmesan
+#include "rotation.cuh"
+
+void cuda_rotate_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          void *lwe_array_in,
+                                          uint32_t k,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count) {
+
+  host_rotation(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in), k, input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+void cuda_rotate_all_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                          void *lwe_array_out,
+                                          void *lwe_array_in,
+                                          uint32_t input_lwe_dimension,
+                                          uint32_t input_lwe_ciphertext_count) {
+
+  host_rotation_all(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in), input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
diff --git a/concrete-cuda/cuda/src/rotation.cuh b/concrete-cuda/cuda/src/rotation.cuh
new file mode 100644
index 00000000..3b4b5a83
--- /dev/null
+++ b/concrete-cuda/cuda/src/rotation.cuh
@@ -0,0 +1,79 @@
+// This file was newly added by the authors of cuparmesan
+#ifndef CUDA_NEGATE_H
+#define CUDA_NEGATE_H
+
+#ifdef __CDT_PARSER__
+#undef __CUDA_RUNTIME_H__
+#include <cuda_runtime.h>
+#include <helper_cuda.h>
+#endif
+
+#include "linear_algebra.h"
+#include "utils/kernel_dimensions.cuh"
+
+template <typename T>
+__global__ void rotation(T *output, T *input, uint32_t k, uint32_t num_entries, uint32_t lwe_size) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries - k*lwe_size) {
+    output[index + k*lwe_size] = input[index];
+  } else if (index < num_entries){
+    output[index - num_entries + k*lwe_size] = input[index];
+  }
+}
+
+template <typename T>
+__host__ void host_rotation(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input, uint32_t k, uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = input_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  rotation<<<grid, thds, 0, *stream>>>(output, input, k, num_entries, lwe_size);
+
+  cudaStreamSynchronize(*stream);
+}
+
+template <typename T>
+__global__ void rotation_all(T *output, T *input, uint32_t num_entries, uint32_t m, uint32_t n) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    uint32_t k = uint32_t(index/(m*n));
+    uint32_t r = uint32_t(index%(m*n));
+    if (r < m*(n-k)) {
+      output[index + k*m] = input[index];
+    } else {
+      output[index + k*m - m*n] = input[index];
+    }
+  }
+}
+
+template <typename T>
+__host__ void host_rotation_all(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input, uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = input_lwe_ciphertext_count * lwe_size;
+  int n = int(sqrt(input_lwe_ciphertext_count));
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  rotation_all<<<grid, thds, 0, *stream>>>(output, input, num_entries, lwe_size, n);
+
+  cudaStreamSynchronize(*stream);
+}
+
+#endif
diff --git a/concrete-cuda/cuda/src/shiftaddition.cu b/concrete-cuda/cuda/src/shiftaddition.cu
new file mode 100644
index 00000000..c7474d48
--- /dev/null
+++ b/concrete-cuda/cuda/src/shiftaddition.cu
@@ -0,0 +1,27 @@
+// This file was newly added by the authors of cuparmesan
+#include "shiftaddition.cuh"
+
+void cuda_sftadd_lwe_ciphertext_vector_64(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       void *lwe_array_in_2,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_shiftaddition(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                static_cast<uint64_t *>(lwe_array_in_2), input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
+
+void cuda_sftadd_lwe_ciphertext_vector_64_inplace(void *v_stream, uint32_t gpu_index,
+                                       void *lwe_array_out,
+                                       void *lwe_array_in_1,
+                                       uint32_t input_lwe_dimension,
+                                       uint32_t input_lwe_ciphertext_count) {
+
+  host_shiftaddition_inplace(v_stream, gpu_index, static_cast<uint64_t *>(lwe_array_out),
+                static_cast<uint64_t *>(lwe_array_in_1),
+                input_lwe_dimension,
+                input_lwe_ciphertext_count);
+}
diff --git a/concrete-cuda/cuda/src/shiftaddition.cuh b/concrete-cuda/cuda/src/shiftaddition.cuh
new file mode 100644
index 00000000..26171eab
--- /dev/null
+++ b/concrete-cuda/cuda/src/shiftaddition.cuh
@@ -0,0 +1,78 @@
+// This file was newly added by the authors of cuparmesan
+#ifndef CUDA_ADD_H
+#define CUDA_ADD_H
+
+#ifdef __CDT_PARSER__
+#undef __CUDA_RUNTIME_H__
+#include <cuda_runtime.h>
+#include <helper_cuda.h>
+#endif
+
+#include "linear_algebra.h"
+#include "utils/kernel_dimensions.cuh"
+
+
+template <typename T>
+__global__ void shiftaddition(T *output, T *input_1, T *input_2,
+                         uint32_t num_entries, uint32_t lwe_size) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    if (index >= lwe_size) {
+      output[index] = input_1[index] + input_2[index - lwe_size];
+    } else {
+      output[index] = input_1[index];
+    }
+  }
+}
+
+template <typename T>
+__host__ void host_shiftaddition(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input_1, T *input_2,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = input_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  shiftaddition<<<grid, thds, 0, *stream>>>(output, input_1, input_2, num_entries, lwe_size);
+
+  cudaStreamSynchronize(*stream);
+}
+
+template <typename T>
+__global__ void shiftaddition_inplace(T *output, T *input,
+                         uint32_t num_entries, uint32_t lwe_size) {
+
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+  if (index < num_entries) {
+    if (index >= lwe_size) {
+      output[index] = output[index] + input[index - lwe_size];
+    }
+  }
+}
+
+template <typename T>
+__host__ void host_shiftaddition_inplace(void *v_stream, uint32_t gpu_index, T *output,
+                            T *input,
+                            uint32_t input_lwe_dimension,
+                            uint32_t input_lwe_ciphertext_count) {
+
+  cudaSetDevice(gpu_index);
+  int lwe_size = input_lwe_dimension + 1;
+  int num_blocks = 0, num_threads = 0;
+  int num_entries = input_lwe_ciphertext_count * lwe_size;
+  getNumBlocksAndThreads(num_entries, 512, num_blocks, num_threads);
+  dim3 grid(num_blocks, 1, 1);
+  dim3 thds(num_threads, 1, 1);
+  auto stream = static_cast<cudaStream_t *>(v_stream);
+  shiftaddition_inplace<<<grid, thds, 0, *stream>>>(output, input, num_entries, lwe_size);
+  cudaStreamSynchronize(*stream);
+}
+
+#endif
diff --git a/concrete-cuda/cuda/src/utils/kernel_dimensions.cuh b/concrete-cuda/cuda/src/utils/kernel_dimensions.cuh
index afd7e008..a24d299c 100644
--- a/concrete-cuda/cuda/src/utils/kernel_dimensions.cuh
+++ b/concrete-cuda/cuda/src/utils/kernel_dimensions.cuh
@@ -1,4 +1,5 @@
-int nextPow2(int x) {
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
+inline int nextPow2(int x) {
   --x;
   x |= x >> 1;
   x |= x >> 2;
@@ -8,8 +9,9 @@ int nextPow2(int x) {
   return ++x;
 }
 
-void getNumBlocksAndThreads(const int n, const int maxBlockSize, int &blocks,
-                            int &threads) {
-  threads = (n < maxBlockSize * 2) ? nextPow2((n + 1) / 2) : maxBlockSize;
+inline void getNumBlocksAndThreads(const int n, const int maxBlockSize,
+                                   int &blocks, int &threads) {
+  threads =
+      (n < maxBlockSize * 2) ? max(128, nextPow2((n + 1) / 2)) : maxBlockSize;
   blocks = (n + threads - 1) / threads;
-}
+}
\ No newline at end of file
diff --git a/concrete-cuda/cuda/src/utils/memory.cuh b/concrete-cuda/cuda/src/utils/memory.cuh
index 88dc500c..13e3037c 100644
--- a/concrete-cuda/cuda/src/utils/memory.cuh
+++ b/concrete-cuda/cuda/src/utils/memory.cuh
@@ -1,3 +1,4 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 #ifndef CNCRT_SHMEM_H
 #define CNCRT_SHMEM_H
 
@@ -9,19 +10,6 @@
 #include <tuple>
 #include <vector>
 
-class SharedMemory {
-public:
-  char *m_memory_block;
-  int m_last_byte;
-
-  __device__ SharedMemory(char *ptr) : m_memory_block(ptr), m_last_byte(0) {}
-
-  template <typename T> __device__ void get_allocation(T **ptr, int elements) {
-    *ptr = (T *)(&this->m_memory_block[m_last_byte]);
-    this->m_last_byte += elements * sizeof(T);
-  }
-};
-
 class DeviceMemory {
 public:
   std::vector<std::tuple<void *, int>> m_allocated;
diff --git a/concrete-cuda/src/cuda_bind.rs b/concrete-cuda/src/cuda_bind.rs
index a7a45e40..45899d4a 100644
--- a/concrete-cuda/src/cuda_bind.rs
+++ b/concrete-cuda/src/cuda_bind.rs
@@ -1,8 +1,11 @@
+// This file is borrowed from the latest version of the  Concrete-core library (1.0.1)
 use std::ffi::c_void;
 
 #[link(name = "concrete_cuda", kind = "static")]
 extern "C" {
 
+    pub fn cuda_pointer_at(lwe_array_in: *mut c_void, gpu_index: u32, i: u32, input_lwe_dimension: u32) -> *mut c_void; // This function was newly added by the authors of cuparmesan
+
     pub fn cuda_create_stream(gpu_index: u32) -> *mut c_void;
 
     pub fn cuda_destroy_stream(v_stream: *mut c_void, gpu_index: u32) -> i32;
@@ -228,4 +231,252 @@ extern "C" {
         level_count_ksk: u32,
         number_of_samples: u32,
     );
+
+    pub fn cuda_negate_lwe_ciphertext_vector_32(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in: *const c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    pub fn cuda_negate_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in: *const c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_rotate_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in: *const c_void,
+        k: u32,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_rotate_all_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in: *const c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_negate_lwe_ciphertext_vector_32_inplace(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_negate_lwe_ciphertext_vector_64_inplace(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    pub fn cuda_add_lwe_ciphertext_vector_32(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        lwe_array_in_2: *const c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    pub fn cuda_add_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        lwe_array_in_2: *const c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_add_inplace_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *const c_void,
+        lwe_array_in: *const c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_add_to_local_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        i: u32,
+        d: u32,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_x_plus_2y_to_local_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        i: u32,
+        d: u32,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_sftadd_from_local_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        lwe_array_in_2: *const c_void,
+        i: u32,
+        d: u32,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_copy_from_local_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        i: u32,
+        d: u32,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_copy_from_local_for_sign_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        i: u32,
+        d: u32,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_and_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        lwe_array_in_2: *const c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_extend_xy_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        lwe_array_in_2: *const c_void,
+        lwe_array_in_3: *const c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_merge_xy_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in: *const c_void,
+        output_lwe_dimension: u32,
+        output_lwe_ciphertext_count: u32,
+    );
+
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_sftadd_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        lwe_array_in_2: *const c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_sftadd_lwe_ciphertext_vector_64_inplace(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_mult_by_const_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        k: u32,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_copy_at_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        i: u32,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_copy_n_at_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        i: u32,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
+
+    // This function was newly added by the authors of cuparmesan
+    pub fn cuda_set_at_lwe_ciphertext_vector_64(
+        v_stream: *const c_void,
+        gpu_index: u32,
+        lwe_array_out: *mut c_void,
+        lwe_array_in_1: *const c_void,
+        i: u32,
+        input_lwe_dimension: u32,
+        input_lwe_ciphertext_count: u32,
+    );
 }
